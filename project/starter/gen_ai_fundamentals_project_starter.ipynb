{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Project: Teaching an LLM to Reason\n",
        "\n",
        "In this project, you will teach an LLM to use step-by-step reasoning to answer the question: \"How many X's are there in the word Y?\"\n",
        "\n",
        "Counting letters in a word is a surprisingly complex task for an LLM. Just as human beings would not be able to answer such a question for longer words without breaking down the word into its individual letters and then counting them, LLMs cannot be similarly expected to be able to respond without using smaller reasoning steps.\n",
        "\n",
        "For example, to count the number of o's in the word room, one could use the following reasoning:\n",
        "\n",
        "```\n",
        "Question: How many of the letter \"o\" are there in the word \"room\"\n",
        "Answer: 2\n",
        "Response:\n",
        "\n",
        "<reasoning>\n",
        "Letter-by-letter spelling:\n",
        "1. r - 0 o's so far\n",
        "2. o - 1 o's so far\n",
        "3. o - 2 o's so far\n",
        "4. m - 2 o's so far\n",
        "\n",
        "The letter \"o\" appears 2 times in the word \"room\".\n",
        "</reasoning>\n",
        "<answer>\n",
        "2\n",
        "</answer>\n",
        "```\n",
        "\n",
        "In this project we will use the reinforcement learning method GRPO (Group Relative Policy Optimization, of DeepSeek fame) to take a large language model that has been fine-tuned for following instructions and teach it how to break a word down into its letters and then count the requested letter.\n",
        "\n",
        "We will complete the following steps:\n",
        "\n",
        "* Set up the notebook\n",
        "* Create a letter-counting dataset\n",
        "* Create the reward functions\n",
        "* Train the model\n",
        "* View the results\n",
        "\n",
        "NOTE: This notebook will have you focus on several important aspects of training a GPRO model using LoRA:\n",
        "\n",
        "1. Configuring LoRA adapters for parameter-efficient fine tuning\n",
        "2. Selecting reward functions that help the model efficiently find its way to the correct answer (also called reward shaping)\n",
        "3. Finding hyperparameters that help the model increase the rewards earned more quickly and reliably\n",
        "4. Learning how to start with smaller experiments and to work your way up to longer experiments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set up the notebook\n",
        "\n",
        "We'll install dependencies needed for the project, namely `unsloth` and `vllm`, which are useful for fine-tuning LLMs with even just 15GB of VRAM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autotime extension is already loaded. To reload it, use:\n",
            "  %reload_ext autotime\n",
            "time: 3.05 s (started: 2025-12-09 09:10:16 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Load ipython-autotime to see how long each cell take to run\n",
        "# No changes needed in this cell\n",
        "\n",
        "!pip install -q ipython-autotime\n",
        "%load_ext autotime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tue Dec  9 09:10:23 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 575.57.08              Driver Version: 575.57.08      CUDA Version: 12.9     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       On  |   00000000:00:1E.0 Off |                    0 |\n",
            "| N/A   24C    P8             13W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 370 ms (started: 2025-12-09 09:10:23 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Verify we have enough GPU memory to run this project (at least 15360MiB)\n",
        "# No changes needed in this cell\n",
        "\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/voc/work/cd13303-genai-c1-classroom/project/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "INFO 12-09 09:21:58 [__init__.py:241] Automatically detected platform cuda.\n",
            "ERROR 12-09 09:22:00 [fa_utils.py:57] Cannot use FA version 2 is not supported due to FA2 is only supported on devices with compute capability >= 8\n",
            "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
            "INFO 12-09 09:22:26 [vllm_utils.py:688] Unsloth: Patching vLLM v1 graph capture\n",
            "INFO 12-09 09:22:26 [vllm_utils.py:716] Unsloth: Patching vLLM v0 graph capture\n",
            "==((====))==  Unsloth 2025.9.7: Fast Qwen2 patching. Transformers: 4.55.4. vLLM: 0.10.1.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.563 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.7.1+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.31. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "Unsloth: vLLM loading unsloth/qwen2.5-3b-instruct-unsloth-bnb-4bit with actual GPU utilization = 49.52%\n",
            "Unsloth: Your GPU has CUDA compute capability 7.5 with VRAM = 14.56 GB.\n",
            "Unsloth: Using conservativeness = 1.0. Chunked prefill tokens = 384. Num Sequences = 192.\n",
            "Unsloth: vLLM's KV Cache can use up to 4.91 GB. Also swap space = 0 GB.\n",
            "WARNING 12-09 09:22:27 [compilation.py:453] full_cuda_graph is deprecated, use cudagraph_mode=FULL instead.\n",
            "Unsloth: Not an error, but `device` is not supported in vLLM. Skipping.\n",
            "INFO 12-09 09:22:27 [utils.py:326] non-default args: {'model': 'unsloth/qwen2.5-3b-instruct-unsloth-bnb-4bit', 'load_format': 'bitsandbytes', 'dtype': torch.float16, 'seed': 0, 'max_model_len': 384, 'enable_prefix_caching': True, 'swap_space': 0, 'gpu_memory_utilization': 0.4952075204419056, 'max_num_batched_tokens': 2048, 'max_num_seqs': 192, 'max_logprobs': 0, 'disable_log_stats': True, 'quantization': 'bitsandbytes', 'enable_lora': True, 'max_lora_rank': 32, 'enable_chunked_prefill': True, 'compilation_config': {\"level\":3,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"inductor\",\"custom_ops\":[],\"splitting_ops\":null,\"use_inductor\":true,\"compile_sizes\":null,\"inductor_compile_config\":{\"epilogue_fusion\":true,\"max_autotune\":false,\"shape_padding\":true,\"trace.enabled\":false,\"triton.cudagraphs\":true,\"debug\":false,\"dce\":true,\"memory_planning\":true,\"coordinate_descent_tuning\":false,\"trace.graph_diagram\":false,\"compile_threads\":4,\"group_fusion\":true,\"disable_progress\":false,\"verbose_progress\":true,\"triton.multi_kernel\":0,\"triton.use_block_ptr\":true,\"triton.enable_persistent_tma_matmul\":true,\"triton.autotune_at_compile_time\":false,\"triton.cooperative_reductions\":false,\"cuda.compile_opt_level\":\"-O2\",\"cuda.enable_cuda_lto\":true,\"combo_kernels\":false,\"benchmark_combo_kernel\":true,\"combo_kernel_foreach_dynamic_shapes\":true,\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"cudagraph_mode\":2,\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":null,\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":true,\"pass_config\":{},\"max_capture_size\":null,\"local_cache_dir\":null}}\n",
            "INFO 12-09 09:22:54 [__init__.py:711] Resolved architecture: Qwen2ForCausalLM\n",
            "WARNING 12-09 09:22:54 [__init__.py:2819] Casting torch.bfloat16 to torch.float16.\n",
            "INFO 12-09 09:22:54 [__init__.py:1750] Using max model len 384\n",
            "WARNING 12-09 09:22:54 [arg_utils.py:1770] Compute Capability < 8.0 is not supported by the V1 Engine. Falling back to V0. \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-09 09:22:55,931\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 12-09 09:22:56 [scheduler.py:222] Chunked prefill is enabled with max_num_batched_tokens=2048.\n",
            "Unsloth: vLLM Bitsandbytes config using kwargs = {'load_in_8bit': False, 'load_in_4bit': True, 'bnb_4bit_compute_dtype': 'float16', 'bnb_4bit_quant_storage': 'uint8', 'bnb_4bit_quant_type': 'nf4', 'bnb_4bit_use_double_quant': True, 'llm_int8_enable_fp32_cpu_offload': False, 'llm_int8_has_fp16_weight': False, 'llm_int8_skip_modules': ['lm_head', 'multi_modal_projector', 'merger', 'modality_projection', 'model.layers.2.mlp', 'model.layers.3.mlp', 'model.layers.30.mlp'], 'llm_int8_threshold': 6.0}\n",
            "INFO 12-09 09:22:56 [llm_engine.py:222] Initializing a V0 LLM engine (v0.10.1) with config: model='unsloth/qwen2.5-3b-instruct-unsloth-bnb-4bit', speculative_config=None, tokenizer='unsloth/qwen2.5-3b-instruct-unsloth-bnb-4bit', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=384, download_dir=None, load_format=bitsandbytes, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=bitsandbytes, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=unsloth/qwen2.5-3b-instruct-unsloth-bnb-4bit, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={\"level\":0,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"inductor\",\"custom_ops\":[],\"splitting_ops\":null,\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"epilogue_fusion\":true,\"max_autotune\":false,\"shape_padding\":true,\"trace.enabled\":false,\"triton.cudagraphs\":true,\"debug\":false,\"dce\":true,\"memory_planning\":true,\"coordinate_descent_tuning\":false,\"trace.graph_diagram\":false,\"compile_threads\":4,\"group_fusion\":true,\"disable_progress\":false,\"verbose_progress\":true,\"triton.multi_kernel\":0,\"triton.use_block_ptr\":true,\"triton.enable_persistent_tma_matmul\":true,\"triton.autotune_at_compile_time\":false,\"triton.cooperative_reductions\":false,\"cuda.compile_opt_level\":\"-O2\",\"cuda.enable_cuda_lto\":true,\"combo_kernels\":false,\"benchmark_combo_kernel\":true,\"combo_kernel_foreach_dynamic_shapes\":true,\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"cudagraph_mode\":2,\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":true,\"pass_config\":{\"enable_fusion\":false,\"enable_noop\":false},\"max_capture_size\":192,\"local_cache_dir\":null}, use_cached_outputs=False, \n",
            "INFO 12-09 09:22:57 [cuda.py:384] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n",
            "INFO 12-09 09:22:57 [cuda.py:433] Using XFormers backend.\n",
            "INFO 12-09 09:22:58 [parallel_state.py:1134] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
            "INFO 12-09 09:22:58 [model_runner.py:1080] Starting to load model unsloth/qwen2.5-3b-instruct-unsloth-bnb-4bit...\n",
            "INFO 12-09 09:22:58 [bitsandbytes_loader.py:742] Loading weights with BitsAndBytes quantization. May take a while ...\n",
            "INFO 12-09 09:22:59 [weight_utils.py:296] Using model weights format ['*.safetensors']\n",
            "INFO 12-09 09:22:59 [weight_utils.py:349] No model.safetensors.index.json found in remote.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
            "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00, 16.39it/s]\n",
            "\n",
            "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
            "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:01<00:00,  1.46s/it]\n",
            "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:01<00:00,  1.46s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 12-09 09:23:01 [punica_selector.py:19] Using PunicaWrapperGPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 12-09 09:23:02 [model_runner.py:1112] Model loading took 2.3277 GiB and 2.833399 seconds\n",
            "INFO 12-09 09:23:13 [worker.py:295] Memory profiling takes 10.72 seconds\n",
            "INFO 12-09 09:23:13 [worker.py:295] the current vLLM instance can use total_gpu_memory (14.56GiB) x gpu_memory_utilization (0.50) = 7.21GiB\n",
            "INFO 12-09 09:23:13 [worker.py:295] model weights take 2.33GiB; non_torch_memory takes 0.03GiB; PyTorch activation peak memory takes 1.05GiB; the rest of the memory reserved for KV Cache is 3.81GiB.\n",
            "INFO 12-09 09:23:13 [executor_base.py:114] # cuda blocks: 6928, # CPU blocks: 0\n",
            "INFO 12-09 09:23:13 [executor_base.py:119] Maximum concurrency for 384 tokens per request: 288.67x\n",
            "INFO 12-09 09:23:13 [vllm_utils.py:721] Unsloth: Running patched vLLM v0 `capture_model`.\n",
            "INFO 12-09 09:23:13 [model_runner.py:1383] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Capturing CUDA graph shapes: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:28<00:00,  1.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 12-09 09:23:41 [model_runner.py:1535] Graph capturing finished in 28 secs, took 0.56 GiB\n",
            "INFO 12-09 09:23:41 [vllm_utils.py:728] Unsloth: Patched vLLM v0 graph capture finished in 28 secs.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 12-09 09:23:42 [llm_engine.py:417] init engine (profile, create kv cache, warmup model) took 40.53 seconds\n",
            "INFO 12-09 09:23:42 [llm.py:298] Supported_tasks: ['generate']\n",
            "Unsloth: Just some info: will skip parsing ['post_feedforward_layernorm', 'post_layernorm', 'pre_feedforward_layernorm', 'norm1', 'norm2', 'post_attention_layernorm', 'q_norm', 'input_layernorm', 'k_norm', 'layer_norm2', 'layer_norm1']\n",
            "Unsloth: Just some info: will skip parsing ['cross_attn_input_layernorm', 'post_feedforward_layernorm', 'post_layernorm', 'pre_feedforward_layernorm', 'norm1', 'norm2', 'post_attention_layernorm', 'cross_attn_post_attention_layernorm', 'q_norm', 'input_layernorm', 'k_norm', 'layer_norm2', 'layer_norm1']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth 2025.9.7 patched 36 layers with 36 QKV layers, 36 O layers and 36 MLP layers.\n"
          ]
        }
      ],
      "source": [
        "# Load the `Qwen 2.5 3B Instruct`, and set parameters for the project\n",
        "# The first time unsloth is imported, it will do its magic and patch the modules\n",
        "# it works with. This may 2-5 minutes.\n",
        "# TODO: Fill in the missing parts marked with **********\n",
        "\n",
        "import unsloth\n",
        "\n",
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "\n",
        "max_seq_length = 384  # Increase if you get errors about the sequence length\n",
        "\n",
        "# Set the LoRA rank to an appropriate value\n",
        "# Read about setting LoRA rank:\n",
        "# https://docs.unsloth.ai/get-started/fine-tuning-llms-guide/lora-hyperparameters-guide\n",
        "# lora_rank = **********  # Explain your choice\n",
        "lora_rank = 32 # Recommended setting was 16-32. I used 32 to gain a more expressiveness. \n",
        "# The higher rank the more resources training will consume.\n",
        "\n",
        "# Load the Instruct model in 4-bit mode\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=\"Qwen/Qwen2.5-3B-Instruct\",\n",
        "    max_seq_length=max_seq_length,\n",
        "    load_in_4bit=True,  # We'll use quantization!\n",
        "    fast_inference=True,  # This uses vllm for faster inference\n",
        "    max_lora_rank=lora_rank,\n",
        "    gpu_memory_utilization=0.5,  # You can reduce this if you get an memory error\n",
        ")\n",
        "\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r=lora_rank,\n",
        "    # Choice of Target Modules: I could go for either only covering \n",
        "    # attention or both attention and MLP. I chose both as the task requires both being aware of context (attention)\n",
        "    # and some reasoning (MLP). Plus it has been recommended in the docs to use both.\n",
        "    target_modules = [\n",
        "        \"q_proj\",    \n",
        "        \"k_proj\",    \n",
        "        \"v_proj\",    \n",
        "        \"o_proj\",    \n",
        "        \"gate_proj\", \n",
        "        \"up_proj\",  \n",
        "        \"down_proj\", \n",
        "    ],\n",
        "    lora_alpha=lora_rank,\n",
        "    use_gradient_checkpointing=\"unsloth\",  # Unsloth enables longer contexts\n",
        "    # See: https://github.com/unslothai/unsloth\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Try Prompt Engineering to Count Letters\n",
        "\n",
        "Let's work on the system prompt a little to see if we can get the model to count the number of the letter `g` in `engage`.\n",
        "\n",
        "\n",
        "Here you must:\n",
        "* Write clear instructions\n",
        "* Break the problem down into steps (Chain-of-Thought prompting)\n",
        "* Provide at least one example for the model to follow (Few-shot prompting)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 1274.09it/s]\n",
            "Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:07<00:00,  7.00s/it, est. speed input: 4.14 toks/s, output: 2.14 toks/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== TEXT FOR COMPLETION ===\n",
            "<|im_start|>system\n",
            "<|im_end|>\n",
            "<|im_start|>user\n",
            "How many of the letter \"g\" are there in the word \"engage\"<|im_end|>\n",
            "<|im_start|>assistant\n",
            "\n",
            "=== GENERATED OUTPUT ===\n",
            "In the word \"engage\", there is only one letter \"g\".\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# First, let's see what happens when we have a blank system prompt\n",
        "# No changes needed in this cell\n",
        "SYSTEM_PROMPT = \"\"\"\"\"\"\n",
        "USER_PROMPT = 'How many of the letter \"g\" are there in the word \"engage\"'\n",
        "\n",
        "# Convert the chat messages to a single string so the model can complete it\n",
        "text_for_completion = tokenizer.apply_chat_template(\n",
        "    conversation=[\n",
        "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": USER_PROMPT,\n",
        "        },\n",
        "    ],\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True,\n",
        ")\n",
        "\n",
        "from vllm import SamplingParams\n",
        "\n",
        "# Set the LLM sampling parameters\n",
        "sampling_params = SamplingParams(\n",
        "    temperature=0.8,\n",
        "    top_p=0.95,\n",
        "    max_tokens=2048,\n",
        ")\n",
        "\n",
        "# Generate the text completion\n",
        "output = (\n",
        "    model.fast_generate(\n",
        "        [text_for_completion],\n",
        "        sampling_params=sampling_params,\n",
        "        lora_request=None,\n",
        "    )[0]\n",
        "    .outputs[0]\n",
        "    .text\n",
        ")\n",
        "\n",
        "# Print the text input for the model and the model's output\n",
        "print(\"=== TEXT FOR COMPLETION ===\")\n",
        "print(text_for_completion)\n",
        "print(\"=== GENERATED OUTPUT ===\")\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Without any prompting the model will generate an output such as this:\n",
        "\n",
        "```\n",
        "=== GENERATED OUTPUT ===\n",
        "There is one letter \"g\" in the word \"engage\".\n",
        "```\n",
        "\n",
        "Now let's work on the system prompt to help the model break this problem down into steps, which might help it get the right answer (2 `g`'s in `engage`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 509.45it/s]\n",
            "Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.97s/it, est. speed input: 36.46 toks/s, output: 7.03 toks/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== TEXT FOR COMPLETION ===\n",
            "<|im_start|>system\n",
            "You are a helpful assistant that counts letters in words. You are admired for your precise results.\n",
            "\n",
            "When asked to count letters you will always follow this process:\n",
            "1. Deconstruct the Words into single letters\n",
            "2. For each letter, check if it matches the requested letter\n",
            "3. Format your response with <reasoning> and <answer> tags\n",
            "\n",
            "Example 1:\n",
            "Question: How many of the letter \"a\" are there in the word \"banana\"\n",
            "<reasoning> The word \"banana\" has the letters: b, a, n, a, n, a. The letter \"a\" appears 3 times. </reasoning> \n",
            "\n",
            "<answer>3</answer>\n",
            "Example 2:\n",
            "Question: How many of the letter \"z\" are there in the word \"sequences\"\n",
            "<reasoning> The word \"sequences\" has the letters: s, e, q, u, e, n, c, e, s. The letter \"z\" appears 0 times. </reasoning> \n",
            "\n",
            "<answer>0</answer>\n",
            "\n",
            "Now apply this process to count letters in words.\n",
            "<|im_end|>\n",
            "<|im_start|>user\n",
            "How many of the letter \"g\" are there in the word \"engage\"<|im_end|>\n",
            "<|im_start|>assistant\n",
            "\n",
            "=== GENERATED OUTPUT ===\n",
            "<reasoning> The word \"engage\" has the letters: e, n, g, a, n, g, e. The letter \"g\" appears 2 times. </reasoning>\n",
            "\n",
            "<answer>2</answer>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Let's work on a new system prompt that will help the model break this problem\n",
        "# down into steps, for example, using \"letter-by-letter\" spelling.\n",
        "# TODO: Fill in the missing parts marked with **********\n",
        "\n",
        "# Use a CoT prompt with at least one example\n",
        "SYSTEM_PROMPT = \"\"\"You are a helpful assistant that counts letters in words. You are admired for your precise results.\n",
        "\n",
        "When asked to count letters you will always follow this process:\n",
        "1. Deconstruct the Words into single letters\n",
        "2. For each letter, check if it matches the requested letter\n",
        "3. Format your response with <reasoning> and <answer> tags\n",
        "\n",
        "Example 1:\n",
        "Question: How many of the letter \"a\" are there in the word \"banana\"\n",
        "<reasoning> The word \"banana\" has the letters: b, a, n, a, n, a. The letter \"a\" appears 3 times. </reasoning> \n",
        "\n",
        "<answer>3</answer>\n",
        "Example 2:\n",
        "Question: How many of the letter \"z\" are there in the word \"sequences\"\n",
        "<reasoning> The word \"sequences\" has the letters: s, e, q, u, e, n, c, e, s. The letter \"z\" appears 0 times. </reasoning> \n",
        "\n",
        "<answer>0</answer>\n",
        "\n",
        "Now apply this process to count letters in words.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "USER_PROMPT = 'How many of the letter \"g\" are there in the word \"engage\"'\n",
        "\n",
        "# Convert the chat messages to a single string so the model can complete it\n",
        "text_for_completion = tokenizer.apply_chat_template(\n",
        "    conversation=[\n",
        "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": USER_PROMPT,\n",
        "        },\n",
        "    ],\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True,\n",
        ")\n",
        "\n",
        "from vllm import SamplingParams\n",
        "\n",
        "# Set the LLM sampling parameters\n",
        "sampling_params = SamplingParams(\n",
        "    temperature=0.8,\n",
        "    top_p=0.95,\n",
        "    max_tokens=2048,\n",
        ")\n",
        "\n",
        "# Generate the text completion\n",
        "output = (\n",
        "    model.fast_generate(\n",
        "        [text_for_completion],\n",
        "        sampling_params=sampling_params,\n",
        "        lora_request=None,\n",
        "    )[0]\n",
        "    .outputs[0]\n",
        "    .text\n",
        ")\n",
        "\n",
        "# Print the text input for the model and the model's output\n",
        "print(\"=== TEXT FOR COMPLETION ===\")\n",
        "print(text_for_completion)\n",
        "print(\"=== GENERATED OUTPUT ===\")\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Did your new prompt get the right answer? Did the model follow all of your instructions?\n",
        "\n",
        "Maybe yes, maybe no. Either way, we'll want the model to reliably complete this challenge. So let's use GRPO to help it!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create a letter-counting dataset\n",
        "\n",
        "To train a model, we'll first need to create a dataset. We'll use the HuggingFace `datasets` package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "62\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['idea',\n",
              " 'glow',\n",
              " 'rust',\n",
              " 'maze',\n",
              " 'echo',\n",
              " 'wisp',\n",
              " 'veto',\n",
              " 'lush',\n",
              " 'gaze',\n",
              " 'knit']"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a list of words of different lengths\n",
        "# No changes are needed in this cell.\n",
        "\n",
        "ALL_WORDS = [\n",
        "    \"idea\",\n",
        "    \"glow\",\n",
        "    \"rust\",\n",
        "    \"maze\",\n",
        "    \"echo\",\n",
        "    \"wisp\",\n",
        "    \"veto\",\n",
        "    \"lush\",\n",
        "    \"gaze\",\n",
        "    \"knit\",\n",
        "    \"fume\",\n",
        "    \"plow\",\n",
        "    \"void\",\n",
        "    \"oath\",\n",
        "    \"grim\",\n",
        "    \"crisp\",\n",
        "    \"lunar\",\n",
        "    \"fable\",\n",
        "    \"quest\",\n",
        "    \"verge\",\n",
        "    \"brawn\",\n",
        "    \"elude\",\n",
        "    \"aisle\",\n",
        "    \"ember\",\n",
        "    \"crave\",\n",
        "    \"ivory\",\n",
        "    \"mirth\",\n",
        "    \"knack\",\n",
        "    \"wryly\",\n",
        "    \"onset\",\n",
        "    \"mosaic\",\n",
        "    \"velvet\",\n",
        "    \"sphinx\",\n",
        "    \"radius\",\n",
        "    \"summit\",\n",
        "    \"banner\",\n",
        "    \"cipher\",\n",
        "    \"glisten\",\n",
        "    \"mantle\",\n",
        "    \"scarab\",\n",
        "    \"expose\",\n",
        "    \"fathom\",\n",
        "    \"tavern\",\n",
        "    \"fusion\",\n",
        "    \"relish\",\n",
        "    \"lantern\",\n",
        "    \"enchant\",\n",
        "    \"torrent\",\n",
        "    \"capture\",\n",
        "    \"orchard\",\n",
        "    \"eclipse\",\n",
        "    \"frescos\",\n",
        "    \"triumph\",\n",
        "    \"absolve\",\n",
        "    \"gossipy\",\n",
        "    \"prelude\",\n",
        "    \"whistle\",\n",
        "    \"resolve\",\n",
        "    \"zealous\",\n",
        "    \"mirage\",\n",
        "    \"aperture\",\n",
        "    \"sapphire\",\n",
        "]\n",
        "\n",
        "print(len(ALL_WORDS))\n",
        "\n",
        "ALL_WORDS[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating train split: 401 examples [00:00, 5160.47 examples/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'words': 'idea', 'letters': 'a', 'counts': 1}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create the dataset as a Hugging Face Dataset using Dataset.from_generator\n",
        "# No changes needed in this cell\n",
        "\n",
        "from datasets import Dataset\n",
        "import random\n",
        "\n",
        "\n",
        "# Go through the letters from the words (as well as letters not in the words),\n",
        "# and create a labelled dataset with all the different combinations.\n",
        "# For example for the word gaze:\n",
        "# 1. How many i's are in idea? <-- count should be 1\n",
        "# 2. How many d's are in idea? <-- count should be 1\n",
        "# 3. How many e's are in idea? <-- count should be 1\n",
        "# 4. How many a's are in idea? <-- count should be 1\n",
        "# 5. How many b's are in idea? <-- a letter not in word (count should be zero)\n",
        "def generate_records():\n",
        "    for word in ALL_WORDS:\n",
        "        for letter in sorted(set(word)):\n",
        "            yield {\"words\": word, \"letters\": letter, \"counts\": word.count(letter)}\n",
        "\n",
        "        # pick random letters not in the word\n",
        "        num_letters_not_in_word_left = int(len(word) // 7 + 1)\n",
        "\n",
        "        random.seed(hash(word))\n",
        "\n",
        "        all_letters = list(\"abcdefghijklmnopqrstuvwxyz\")\n",
        "\n",
        "        random.shuffle(all_letters)\n",
        "        for letter in all_letters:\n",
        "            if letter not in word:\n",
        "                yield {\"words\": word, \"letters\": letter, \"counts\": 0}\n",
        "                num_letters_not_in_word_left -= 1\n",
        "            if num_letters_not_in_word_left == 0:\n",
        "                break\n",
        "\n",
        "\n",
        "ds = Dataset.from_generator(generate_records)\n",
        "\n",
        "# Show the first item\n",
        "ds[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 401/401 [00:00<00:00, 4367.95 examples/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'words': 'idea',\n",
              " 'letters': 'a',\n",
              " 'counts': 1,\n",
              " 'prompt': [{'content': \"\\nRespond in the following format:\\n<reasoning>\\nCounting the number of [letter_to_count]'s in the word [word]\\n1. [first letter] - [count of requested letter so far] so far\\n2. [second letter] - [count of requested letter so far] so far\\n...\\n</reasoning>\\n<answer>\\n[number]\\n</answer>\\n\",\n",
              "   'role': 'system'},\n",
              "  {'content': 'How many of the letter \"a\" are there in the word \"idea\"',\n",
              "   'role': 'user'}]}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Add the entire prompt (system + user) and the answer to the dataset\n",
        "# We'll use a prompt that spells out the word letter-by-letter\n",
        "# No changes needed in this cell\n",
        "\n",
        "import re\n",
        "from datasets import load_dataset, Dataset\n",
        "\n",
        "# Simple CoT prompt (zero-shot)\n",
        "SYSTEM_PROMPT = \"\"\"\n",
        "Respond in the following format:\n",
        "<reasoning>\n",
        "Counting the number of [letter_to_count]'s in the word [word]\n",
        "1. [first letter] - [count of requested letter so far] so far\n",
        "2. [second letter] - [count of requested letter so far] so far\n",
        "...\n",
        "</reasoning>\n",
        "<answer>\n",
        "[number]\n",
        "</answer>\n",
        "\"\"\"\n",
        "\n",
        "ds = ds.map(\n",
        "    lambda x: {  # type: ignore\n",
        "        \"prompt\": [\n",
        "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": 'How many of the letter \"{}\" are there in the word \"{}\"'.format(\n",
        "                    x[\"letters\"], x[\"words\"]\n",
        "                ),\n",
        "            },\n",
        "        ],\n",
        "    }\n",
        ")\n",
        "\n",
        "ds[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 58.32it/s]\n",
            "Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.71s/it, est. speed input: 61.48 toks/s, output: 38.06 toks/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<reasoning>\n",
            "Counting the number of a's in the word idea\n",
            "1. i - 1 so far\n",
            "2. d - 1 so far\n",
            "3. e - 1 so far\n",
            "4. a - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Let's see how well the model runs out-of-the-box\n",
        "# No changes needed in this cell\n",
        "\n",
        "text = tokenizer.apply_chat_template(\n",
        "    ds[0][\"prompt\"], tokenize=False, add_generation_prompt=True\n",
        ")\n",
        "\n",
        "from vllm import SamplingParams\n",
        "\n",
        "sampling_params = SamplingParams(\n",
        "    temperature=0.8,\n",
        "    top_p=0.95,\n",
        "    max_tokens=1024,\n",
        ")\n",
        "output = (\n",
        "    model.fast_generate(\n",
        "        [text],\n",
        "        sampling_params=sampling_params,\n",
        "        lora_request=None,\n",
        "    )[0]\n",
        "    .outputs[0]\n",
        "    .text\n",
        ")\n",
        "\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Reward Functions\n",
        "\n",
        "One goal of creating reward functions is to guide the model toward behaviors that help it reach its goal (counting the occurrences of a letter within a word) more easily. Since there is more than one way to carry out any step-by-step task (e.g. whether or not you use bullet points to separate your steps), there's a bit of judgement involved in choosing what behaviors to reward, i.e. how do we provide partial credit or \"shape\" our rewards?\n",
        "\n",
        "In this case we will encourage the model to (whether or not this structure is best):\n",
        "* use numbers for bullet points when spelling out the word\n",
        "* to spell the word correctly\n",
        "* to count the requested letter correctly\n",
        "* to use the requested reasoning format\n",
        "* to get the final answer correct.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Numbering reward function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-0.625, 0.625]\n"
          ]
        }
      ],
      "source": [
        "# Let's work on a function that the numbering in the bullet points is correct\n",
        "# When using GRPO, we lean on reward functions that are relatively easy to\n",
        "# compute, thus removing the need to have a second large model just for\n",
        "# evaluation.\n",
        "# In this case, we'll use regular expressions quite a bit.\n",
        "# TODO: Fill in the missing parts marked with **********\n",
        "\n",
        "\n",
        "def extract_letter_numbering(response):\n",
        "    \"\"\"Extract the numbers at the beginning of the line\n",
        "\n",
        "    Example:\n",
        "    1. g - 1 so far\n",
        "    2. o - 1 so far\n",
        "    3. a - 2 so far\n",
        "    4. a - 2 so far\n",
        "    5. l - 2 so far\n",
        "    returns [1, 2, 3, 4, 5]\n",
        "    \"\"\"\n",
        "    import re\n",
        "\n",
        "    # We use a regular expression to find lines of the form:\n",
        "    # '\\n[number]. [letter]'\n",
        "    pattern = r\"\\n(\\d+). [a-z]\"\n",
        "\n",
        "    # Use `re` to find all matches of the pattern in the response\n",
        "    matches = re.findall(pattern, response)\n",
        "    if matches:\n",
        "        return [int(m) for m in matches]\n",
        "    return []\n",
        "\n",
        "\n",
        "assert extract_letter_numbering(\n",
        "    \"\"\"\n",
        "1. g - 1 so far\n",
        "2. o - 1 so far\n",
        "3. a - 2 so far\n",
        "4. a - 2 so far\n",
        "5. l - 2 so far\n",
        "\"\"\"\n",
        ") == [1, 2, 3, 4, 5]\n",
        "\n",
        "\n",
        "def numbering_reward_func(completions, words, **kwargs) -> list[float]:\n",
        "    \"\"\"Provides a reward for getting the numbering at the beginning of the line correct\n",
        "\n",
        "    1. g - 1 so far <-- Good in-order numbering\n",
        "    2. o - 1 so far <-- Good in-order numbering\n",
        "    3. a - 2 so far <-- Good in-order numbering\n",
        "    3. l - 2 so far <-- Bad numbering, out-of-order, 3 should be 4\n",
        "    1. l - 2 so far <-- Bad numbering, extra letter and out-of-order\n",
        "    1. l - 2 so far <-- Bad numbering, extra letter and out-of-order\n",
        "\n",
        "    \"\"\"\n",
        "    responses = [completion[0][\"content\"] for completion in completions]\n",
        "\n",
        "    res = []\n",
        "    for response, word in zip(responses, words):\n",
        "        reward = 0\n",
        "\n",
        "        for ix, spell_number in enumerate(extract_letter_numbering(response)):\n",
        "            line_number = ix + 1\n",
        "\n",
        "            # Get points for in-order numbering\n",
        "            if spell_number == line_number:\n",
        "                # TODO: Provide a reward for in-order numbering\n",
        "                # (positive for good behavior, negative for bad)\n",
        "                reward += 1.0\n",
        "            # Otherwise lose points\n",
        "            else:\n",
        "                # TODO: Provide a reward for out-of-order numbering\n",
        "                # (positive for good behavior, negative for bad)\n",
        "                reward -= 0.5\n",
        "\n",
        "            # Lose extra points for continuing beyond the length of the word\n",
        "            if line_number > len(word):  # We use the index of the line\n",
        "                # TODO: Provide a reward for continuing beyond the length of the word\n",
        "                # (positive for good behavior, negative for bad)\n",
        "                 reward -= 2.0\n",
        "\n",
        "        res.append(reward / len(word))\n",
        "    return res\n",
        "\n",
        "\n",
        "res = numbering_reward_func(\n",
        "    completions=[\n",
        "        [\n",
        "            {  # Worse response\n",
        "                \"content\": \"\"\"<reasoning>\n",
        "Here is a letter by letter spelling:\n",
        "1. g - 1 so far <-- Good in-order numbering\n",
        "2. o - 1 so far <-- Good in-order numbering\n",
        "3. a - 2 so far <-- Good in-order numbering\n",
        "3. l - 2 so far <-- Bad numbering, out-of-order, 3 should be 4\n",
        "1. l - 2 so far <-- Bad numbering, extra letter and out-of-order\n",
        "1. l - 2 so far <-- Bad numbering, extra letter and out-of-order\n",
        "</reasoning>\n",
        "<answer>2</answer>\"\"\"\n",
        "            },\n",
        "        ],\n",
        "        [\n",
        "            {  # Better response\n",
        "                \"content\": \"\"\"<reasoning>\n",
        "Here is a letter by letter spelling:\n",
        "1. g - 1 so far <-- Good in-order numbering\n",
        "2. o - 1 so far <-- Good in-order numbering\n",
        "3. a - 2 so far <-- Good in-order numbering\n",
        "3. l - 2 so far <-- Bad numbering, out-of-order, 3 should be 4\n",
        "</reasoning>\n",
        "<answer>2</answer>\"\"\"\n",
        "            },\n",
        "        ],\n",
        "    ],\n",
        "    words=[\"goal\", \"goal\"],\n",
        ")\n",
        "print(res)\n",
        "\n",
        "assert res[1] > res[0], \"The better response should have a higher reward\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Spelling reward function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-0.5, 5.0]\n"
          ]
        }
      ],
      "source": [
        "# Reward correct spelling of the word\n",
        "# TODO: Fill in the missing parts marked with **********\n",
        "\n",
        "\n",
        "def extract_spelling(response):\n",
        "    \"\"\"Extract the spelling from the response\n",
        "\n",
        "    Example:\n",
        "    1. g - 1 so far\n",
        "    2. o - 1 so far\n",
        "    3. a - 2 so far\n",
        "    3. l - 2 so far\n",
        "    5. l - 2 so far\n",
        "    Returns \"goall\"\n",
        "    \"\"\"\n",
        "    import re\n",
        "\n",
        "    pattern = r\"\\n\\d+. ([a-z])\"\n",
        "    matches = re.findall(pattern, response, flags=re.IGNORECASE)\n",
        "    if matches:\n",
        "        return \"\".join([m for m in matches])\n",
        "    return \"\"\n",
        "\n",
        "\n",
        "extract_spelling(\n",
        "    \"\"\"Here is a letter by letter spelling:\n",
        "\n",
        "1. g - 1 so far\n",
        "2. o - 1 so far\n",
        "3. a - 2 so far\n",
        "3. l - 2 so far\n",
        "5. l - 2 so far\n",
        "\"\"\"\n",
        ") == \"goall\"\n",
        "\n",
        "\n",
        "def spelling_reward_func(completions, words, **kwargs) -> list[float]:\n",
        "    \"\"\"A spelling reward function.\"\"\"\n",
        "    from collections import Counter\n",
        "\n",
        "    responses = [completion[0][\"content\"] for completion in completions]\n",
        "\n",
        "    res = []\n",
        "\n",
        "    for word, response in zip(words, responses):\n",
        "        reward = 0.0\n",
        "\n",
        "        # Provide a reward for exactly correct spelling\n",
        "        if extract_spelling(response) == word:\n",
        "             reward += 5.0\n",
        "\n",
        "        # Provide a reward for each letter of difference in length\n",
        "        reward -= abs(len(extract_spelling(response)) - len(word)) * 0.5\n",
        "\n",
        "        # Provide a reward for each letter that is not in the target word\n",
        "        for letter, count in Counter(extract_spelling(response)).items():\n",
        "            if letter not in Counter(word):\n",
        "                reward -= count * 0.5\n",
        "\n",
        "        # Provide a reward for each letter that is in the target word but not in the response\n",
        "        for letter, count in Counter(word).items():\n",
        "            if letter not in Counter(extract_spelling(response)):\n",
        "                reward -= count * 0.5\n",
        "\n",
        "        res.append(reward)\n",
        "    return res\n",
        "\n",
        "\n",
        "res = spelling_reward_func(\n",
        "    completions=[\n",
        "        [  # Worse response\n",
        "            {\n",
        "                \"content\": \"\"\"<reasoning>\n",
        "Here is a letter by letter spelling:\n",
        "1. g - 1 so far\n",
        "2. o - 1 so far\n",
        "3. a - 2 so far\n",
        "4. l - 2 so far\n",
        "5. l - 2 so far\n",
        "</reasoning>\n",
        "<answer>2</answer>\"\"\"\n",
        "            }\n",
        "        ],\n",
        "        [  # Better Response\n",
        "            {\n",
        "                \"content\": \"\"\"<reasoning>\n",
        "Here is a letter by letter spelling:\n",
        "1. g - 1 so far\n",
        "2. o - 1 so far\n",
        "3. a - 2 so far\n",
        "4. l - 2 so far\n",
        "</reasoning>\n",
        "<answer>2</answer>\"\"\"\n",
        "            }\n",
        "        ],\n",
        "    ],\n",
        "    words=[\"goal\", \"goal\"],\n",
        ")\n",
        "\n",
        "print(res)\n",
        "\n",
        "assert res[1] > res[0], \"The better response should have a higher reward\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Counting reward function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-0.2, 1.0]\n"
          ]
        }
      ],
      "source": [
        "# Let's reward the model for properly counting the occurrences of a letter in a word\n",
        "# TODO: Fill in the missing parts marked with **********\n",
        "# No changes needed in this cell, but feel free to experiment with variations on the prompt\n",
        "\n",
        "\n",
        "def get_resp_letters_and_counts(response):\n",
        "    \"\"\"Extract the letters and counts from the response\n",
        "\n",
        "    Example:\n",
        "    1. g - 1 so far\n",
        "    2. o - 1 so far\n",
        "    3. a - 2 so far\n",
        "    4. a - 2 so far\n",
        "    5. l - 2 so far\n",
        "    returns [('g', 1), ('o', 1), ('a', 2), ('a', 2), ('l', 2)]\n",
        "    \"\"\"\n",
        "    import re\n",
        "\n",
        "    pattern = r\"\\n(\\d+)\\. ([a-z])\\D*(\\d+)\"\n",
        "\n",
        "    # Find strings matching e.g. \"2. a - 2 so far\"\n",
        "    matches = re.findall(pattern, response, flags=re.IGNORECASE)\n",
        "\n",
        "    if not matches:\n",
        "        return []\n",
        "\n",
        "    return [\n",
        "        (matched_letter, matched_count_so_far)\n",
        "        for _, matched_letter, matched_count_so_far in matches\n",
        "    ]\n",
        "\n",
        "\n",
        "assert get_resp_letters_and_counts(\n",
        "    \"\"\"\n",
        "1. g - 1 so far\n",
        "2. o - 1 so far\n",
        "3. a - 2 so far\n",
        "4. a - 2 so far\n",
        "5. l - 2 so far\n",
        "\"\"\"\n",
        ") == [(\"g\", \"1\"), (\"o\", \"1\"), (\"a\", \"2\"), (\"a\", \"2\"), (\"l\", \"2\")]\n",
        "\n",
        "\n",
        "def counting_reward_func(completions, letters, **kwargs) -> list[float]:\n",
        "    responses = [completion[0][\"content\"] for completion in completions]\n",
        "\n",
        "    res = []\n",
        "\n",
        "    # Iterate over each of the letter-response pairs\n",
        "    for letter, response in zip(letters, responses):\n",
        "        reward = 0\n",
        "\n",
        "        letters_and_counts = get_resp_letters_and_counts(response)\n",
        "\n",
        "        # If there are no matches, provide a negative reward\n",
        "        if not letters_and_counts:\n",
        "            res.append(-1)\n",
        "            continue\n",
        "\n",
        "        # Start counting the matching letters\n",
        "        actual_count = 0\n",
        "        for resp_letter, resp_count in letters_and_counts:\n",
        "            # If there's a match, count the letter\n",
        "            if letter == resp_letter:\n",
        "                actual_count += 1\n",
        "\n",
        "            # If the count is accurate, add a reward, else subtract a reward\n",
        "            if int(resp_count) == actual_count:\n",
        "                reward += 1.0\n",
        "            else:\n",
        "                reward -= 0.5\n",
        "\n",
        "        # Return the reward normalized by the length of the matches\n",
        "        res.append(reward / len(letters_and_counts))\n",
        "    return res\n",
        "\n",
        "\n",
        "res = counting_reward_func(\n",
        "    completions=[\n",
        "        [  # Worse response\n",
        "            {\n",
        "                \"content\": \"\"\"<reasoning>\\nHere is a letter by letter spelling:\n",
        "\n",
        "1. g - 0 so far\n",
        "2. o - 0 so far\n",
        "3. a - 1 so far\n",
        "4. a - 2 so far\n",
        "5. l - 0 so far\n",
        "\n",
        "\\n</reasoning>\\n<answer>\\nThis is my answer.\\n</answer>\"\"\"\n",
        "            }\n",
        "        ],\n",
        "        [  # Better response\n",
        "            {\n",
        "                \"content\": \"\"\"<reasoning>\\nHere is a letter by letter spelling:\n",
        "\n",
        "1. g - 1 so far\n",
        "2. o - 1 so far\n",
        "3. a - 1 so far\n",
        "4. a - 1 so far\n",
        "5. l - 1 so far\n",
        "\n",
        "\\n</reasoning>\\n<answer>\\nThis is my answer.\\n</answer>\"\"\"\n",
        "            }\n",
        "        ],\n",
        "    ],\n",
        "    letters=[\"g\", \"g\"],\n",
        ")\n",
        "\n",
        "print(res)\n",
        "\n",
        "assert res[1] > res[0], \"The better response should have a higher reward\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Formatting reward functions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.0, 1.0]\n"
          ]
        }
      ],
      "source": [
        "# Reward the model for providing the response in a specific format\n",
        "# TODO: Fill in the missing parts marked with **********\n",
        "\n",
        "\n",
        "def extract_xml_answer(text: str) -> str:\n",
        "    \"\"\"Extracts the string between <answer> and </answer> tags.\"\"\"\n",
        "    import re\n",
        "\n",
        "    pattern = r\"<answer>(.*?)</answer>\"\n",
        "    match = re.search(pattern, text, re.DOTALL)\n",
        "    if match:\n",
        "        return match.group(1).strip()\n",
        "    return \"\"\n",
        "\n",
        "\n",
        "assert (\n",
        "    extract_xml_answer(\"\"\"\n",
        "<reasoning>\n",
        "This is my reasoning.\n",
        "</reasoning>\n",
        "<answer>SUPERCALIFRAGILISTICEXPIALIDOCIOUS</answer>\n",
        "\"\"\")\n",
        "    == \"SUPERCALIFRAGILISTICEXPIALIDOCIOUS\"\n",
        ")\n",
        "\n",
        "\n",
        "def format_reward_func(completions, **kwargs) -> list[float]:\n",
        "    \"\"\"Reward function that checks if the completion has a specific format.\"\"\"\n",
        "    pattern = r\"\\s*<reasoning>.*?</reasoning>\\s*<answer>.*?</answer>\"\n",
        "\n",
        "    res = []\n",
        "\n",
        "    for completion in completions:\n",
        "        reward = 0.0\n",
        "\n",
        "        # Extract the response content\n",
        "        response = completion[0][\"content\"]\n",
        "\n",
        "        # Check if the response matches the pattern\n",
        "        match = re.match(pattern, response, flags=re.MULTILINE | re.DOTALL)\n",
        "\n",
        "        # If it matches, return 0.5, otherwise return 0.0\n",
        "        if match:\n",
        "            reward += 0.5\n",
        "        \n",
        "        # Extract the answer from the response\n",
        "        extracted_answer = extract_xml_answer(response)\n",
        "        # If the answer is an integer, add 0.5 to the reward\n",
        "        if extracted_answer:\n",
        "            try:\n",
        "                int(extracted_answer)\n",
        "                reward += 0.5\n",
        "            except ValueError:\n",
        "                pass\n",
        "        res.append(reward)\n",
        "    return res\n",
        "    # No need to normalize here, there is 1.0 for a perfect response which is 0.5 per response part.\n",
        "\n",
        "res = format_reward_func(\n",
        "    completions=[\n",
        "        [{\"content\": \"This is my answer\"}],\n",
        "        [\n",
        "            {\n",
        "                \"content\": \"<reasoning>\\nThis is my reasoning.\\n</reasoning>\\n<answer>\\n3\\n</answer>\"\n",
        "            }\n",
        "        ],\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(res)\n",
        "\n",
        "assert res[1] > res[0], \"The better response should have a higher reward\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Task correctness reward function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--------------------\n",
            "Question: How many...\n",
            "Answer: 0\n",
            "Response: <reasoning>.../reasoning>\n",
            "<answer>\n",
            "3\n",
            "</answer>\n",
            "Extracted: 3\n",
            "Correct: False!\n",
            "    \n",
            "[0.0, 2.0]\n"
          ]
        }
      ],
      "source": [
        "# Reward the model for providing the correct answer\n",
        "# TODO: Fill in the missing parts marked with **********\n",
        "\n",
        "\n",
        "def correct_answer_reward_func(prompts, completions, counts, **kwargs) -> list[float]:\n",
        "    \"\"\"Reward the final answer if it is correct.\"\"\"\n",
        "    responses = [completion[0][\"content\"] for completion in completions]\n",
        "\n",
        "    extracted_responses = [extract_xml_answer(r) for r in responses]\n",
        "\n",
        "    # Print a nice summary of the first prompt, answer, and response to see while training\n",
        "    print(f\"\"\"\n",
        "{\"-\" * 20}\n",
        "Question: {prompts[0][-1][\"content\"]}\n",
        "Answer: {counts[0]}\n",
        "Response: {responses[0]}\n",
        "Extracted: {extracted_responses[0]}\n",
        "Correct: {str(extracted_responses[0]) == str(counts[0])}!\n",
        "    \"\"\")\n",
        "\n",
        "    res = [\n",
        "        # Provide reward for exactly correct answer\n",
        "        # **********  # Complete the list comprehension\n",
        "        2.0 if str(r) == str(a) else 0.0\n",
        "        for r, a in zip(extracted_responses, counts)\n",
        "    ]\n",
        "    return res\n",
        "\n",
        "\n",
        "res = correct_answer_reward_func(\n",
        "    prompts=[\n",
        "        [{\"content\": \"\"\"How many...\"\"\"}],\n",
        "        [{\"content\": \"\"\"How many...\"\"\"}],\n",
        "    ],\n",
        "    completions=[\n",
        "        [{\"content\": \"\"\"<reasoning>.../reasoning>\\n<answer>\\n3\\n</answer>\"\"\"}],\n",
        "        [{\"content\": \"\"\"<reasoning>.../reasoning>\\n<answer>\\n3\\n</answer>\"\"\"}],\n",
        "    ],\n",
        "    letters=[\"g\", \"g\"],\n",
        "    counts=[0, 3],\n",
        ")\n",
        "\n",
        "print(res)\n",
        "\n",
        "assert res[1] > res[0], \"The better response should have a higher reward\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### List the reward functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List out the reward functions we will use\n",
        "# No changes needed in this cell\n",
        "\n",
        "REWARD_FUNCS = [\n",
        "    numbering_reward_func,\n",
        "    spelling_reward_func,\n",
        "    counting_reward_func,\n",
        "    format_reward_func,\n",
        "    correct_answer_reward_func,\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train the model\n",
        "\n",
        "Now set up GRPO Trainer and configurations!\n",
        "\n",
        "As you run the trainer, the goal is to see the various `reward` columns increase.\n",
        "\n",
        "After 50 steps or more, you may notice some of the reward standard deviations begin to decrease, meaning that the different predictions are starting to converge on solutions that give similar rewards. If your model has learned the task, then you'll see the `correct_answer_reward_function` increase to its highest value (check the function to see what that is).\n",
        "\n",
        "Here is an example, which successfully converged on a higher reward. Note, the values you see here will probably be different from yours, especially if your reward amounts are different.\n",
        "\n",
        "| Step | Training Loss | reward   | reward_std | ... | kl      | rewards / correct_answer_reward_function / mean | rewards / correct_answer_reward_function / std |\n",
        "|------|---------------|----------|------------|-----|---------|------------------------------------------|-----------------------------------------|\n",
        "| 1    | 0.000000      | 7.961805 | 2.368493   | ... | 0.020369| 0.875000                                 | 1.024695                                |\n",
        "| 2    | 0.000000      | 7.937500 | 1.352467   | ... | 0.016483| 0.875000                                 | 1.024695                                |\n",
        "| 3    | 0.000000      | 1.894792 | 6.462189   | ... | 0.013677| 0.375000                                 | 0.806226                                |\n",
        "| ...  | ...           | ...      | ...        | ... | ...     | ...                                      | ...                                     |\n",
        "| 398  | 0.000100      | 13.000000| 0.000000   | ... | 0.088529| 2.000000                                 | 0.000000                                |\n",
        "| 399  | 0.000100      | 13.000000| 0.000000   | ... | 0.088617| 2.000000                                 | 0.000000                                |\n",
        "| 400  | 0.000100      | 13.000000| 0.000000   | ... | 0.096202| 2.000000                                 | 0.000000                                |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fill in the GRPO Parameters we'll use throughout this project\n",
        "# TODO: Fill in the missing parts marked with **********\n",
        "\n",
        "# Read about the GRPO params here https://huggingface.co/docs/trl/main/en/grpo_trainer\n",
        "COMMON_GRPO_TRAINING_PARAMS = dict(\n",
        "    # Set appropriate values for `learning_rate` and `beta`\n",
        "    # See: https://docs.unsloth.ai/get-started/fine-tuning-llms-guide/lora-hyperparameters-guide\n",
        "    # See: https://huggingface.co/docs/trl/main/en/grpo_trainer\n",
        "    learning_rate=5e-6,  # Recommended for GRPO Reinforcement Learning based on the documentation\n",
        "    beta=0.04, # moderate starting point\n",
        "    # Set the batch size appropriately for your hardware. For GRPO there are a number of parameters to set.\n",
        "    # If you are not sure about your GPU, assume you have a T4. See the memory specs here:\n",
        "    # https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/tesla-product-literature/T4%20Product%20Brief.pdf\n",
        "    per_device_train_batch_size=8, # per_device_train_batch_size / num_generations determines the number of simultaneous prompts to consider.\n",
        "    # Note: Set per_device_train_batch_size to at most 16 on the Vocareum T4 for best stability\n",
        "    num_generations=4,  # Determines the number of completions/generations to compute for each single prompt\n",
        "    gradient_accumulation_steps=2,  # This parameter allow us to consider multiple steps in a single optimization step\n",
        "    adam_beta1=0.9,\n",
        "    adam_beta2=0.99,\n",
        "    weight_decay=0.1,\n",
        "    warmup_ratio=0.1,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    optim=\"adamw_8bit\",\n",
        "    logging_steps=1,\n",
        "    max_prompt_length=256,\n",
        "    max_completion_length=200,\n",
        "    num_train_epochs=1,  # Set to 1 for a full training run\n",
        "    save_steps=250,\n",
        "    max_grad_norm=0.1,\n",
        "    report_to=\"none\",  # Setting this value lets us use Weights and Biases\n",
        "    output_dir=\"outputs\",\n",
        "    use_vllm=True,  # vll speeds up inference! See https://github.com/vllm-project/vllm\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Quick train\n",
        "\n",
        "Let's train the model for just 5 steps (`max_steps=5`). As it runs we can double check we've set up our prompts correctly before running for a longer amount of time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 401 | Num Epochs = 1 | Total steps = 5\n",
            "O^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 2\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 2 x 1) = 16\n",
            " \"-____-\"     Trainable parameters = 59,867,136 of 3,145,805,824 (1.90% trained)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"g\" are there in the word \"glisten\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of g's in the word glisten\n",
            "1. g - 1 so far\n",
            "2. i - 1 so far\n",
            "3. n - 1 so far\n",
            "4. s - 1 so far\n",
            "5. t - 1 so far\n",
            "6. e - 1 so far\n",
            "7. l - 1 so far\n",
            "8. n - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "Unsloth: Will smartly offload gradients to save VRAM!\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5/5 01:08, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>reward</th>\n",
              "      <th>reward_std</th>\n",
              "      <th>completions / mean_length</th>\n",
              "      <th>completions / min_length</th>\n",
              "      <th>completions / max_length</th>\n",
              "      <th>completions / clipped_ratio</th>\n",
              "      <th>completions / mean_terminated_length</th>\n",
              "      <th>completions / min_terminated_length</th>\n",
              "      <th>completions / max_terminated_length</th>\n",
              "      <th>kl</th>\n",
              "      <th>rewards / numbering_reward_func / mean</th>\n",
              "      <th>rewards / numbering_reward_func / std</th>\n",
              "      <th>rewards / spelling_reward_func / mean</th>\n",
              "      <th>rewards / spelling_reward_func / std</th>\n",
              "      <th>rewards / counting_reward_func / mean</th>\n",
              "      <th>rewards / counting_reward_func / std</th>\n",
              "      <th>rewards / format_reward_func / mean</th>\n",
              "      <th>rewards / format_reward_func / std</th>\n",
              "      <th>rewards / correct_answer_reward_func / mean</th>\n",
              "      <th>rewards / correct_answer_reward_func / std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.492708</td>\n",
              "      <td>1.841849</td>\n",
              "      <td>85.562500</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>119.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>85.562500</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>119.000000</td>\n",
              "      <td>0.000021</td>\n",
              "      <td>0.816964</td>\n",
              "      <td>0.250467</td>\n",
              "      <td>1.125000</td>\n",
              "      <td>2.789863</td>\n",
              "      <td>0.175744</td>\n",
              "      <td>0.497200</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.375000</td>\n",
              "      <td>0.957427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.702865</td>\n",
              "      <td>1.892045</td>\n",
              "      <td>82.937500</td>\n",
              "      <td>57.000000</td>\n",
              "      <td>113.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>82.937500</td>\n",
              "      <td>57.000000</td>\n",
              "      <td>113.000000</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>0.874219</td>\n",
              "      <td>0.153465</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>2.780887</td>\n",
              "      <td>0.203646</td>\n",
              "      <td>0.397407</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.125000</td>\n",
              "      <td>1.024695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.586309</td>\n",
              "      <td>2.243013</td>\n",
              "      <td>91.062500</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>182.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>91.062500</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>182.000000</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.953869</td>\n",
              "      <td>0.088007</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>2.642600</td>\n",
              "      <td>0.632441</td>\n",
              "      <td>0.437967</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.375000</td>\n",
              "      <td>0.957427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.501386</td>\n",
              "      <td>2.734426</td>\n",
              "      <td>93.187500</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>86.066673</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>0.000039</td>\n",
              "      <td>0.781250</td>\n",
              "      <td>0.546771</td>\n",
              "      <td>1.656250</td>\n",
              "      <td>3.767045</td>\n",
              "      <td>-0.123614</td>\n",
              "      <td>0.348012</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.683130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.239212</td>\n",
              "      <td>1.632579</td>\n",
              "      <td>70.375000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>70.375000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>0.000049</td>\n",
              "      <td>0.847470</td>\n",
              "      <td>0.288027</td>\n",
              "      <td>1.125000</td>\n",
              "      <td>3.844910</td>\n",
              "      <td>0.391741</td>\n",
              "      <td>0.554836</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>1.024695</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"e\" are there in the word \"sapphire\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of e's in the word sapphire\n",
            "1. s - 0 so far\n",
            "2. a - 1 so far\n",
            "3. p - 1 so far\n",
            "4. h - 1 so far\n",
            "5. a - 2 so far\n",
            "6. r - 2 so far\n",
            "7. p - 3 so far\n",
            "8. y - 3 so far\n",
            "9. e - 4 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "4\n",
            "</answer>\n",
            "Extracted: 4\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"g\" are there in the word \"absolve\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of g's in the word absolve\n",
            "1. a - 0 so far\n",
            "2. b - 0 so far\n",
            "3. s - 0 so far\n",
            "4. g - 0 so far\n",
            "5. l - 0 so far\n",
            "6. e - 0 so far\n",
            "So, there are 0 letters \"g\" in the word \"absolve\".\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"g\" are there in the word \"mirage\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of g's in the word \"mirage\"\n",
            "1. m - 0 so far\n",
            "2. i - 1 so far\n",
            "3. r - 0 so far\n",
            "4. a - 1 so far\n",
            "5. g - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"r\" are there in the word \"crave\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of r's in the word crave\n",
            "1. c - 0 so far\n",
            "2. r - 1 so far\n",
            "3. a - 1 so far\n",
            "4. v - 1 so far\n",
            "5. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n"
          ]
        }
      ],
      "source": [
        "# Train for just a few steps for a few minutes\n",
        "# This will allow us to observe the results and make any changes to our reward functions\n",
        "# before starting a longer run. Note, you won't see much change in the average.\n",
        "# reward values\n",
        "# No changes are needed here\n",
        "\n",
        "from trl import GRPOConfig, GRPOTrainer\n",
        "\n",
        "# Short train to check on reward functions\n",
        "training_args = GRPOConfig(\n",
        "    **COMMON_GRPO_TRAINING_PARAMS,\n",
        "    # We'll just run for a modest 5 steps to make sure everything works and to\n",
        "    # estimate the amount of time it will take to run the full training.\n",
        "    max_steps=5,\n",
        ")\n",
        "trainer = GRPOTrainer(\n",
        "    model=model,\n",
        "    processing_class=tokenizer,\n",
        "    reward_funcs=REWARD_FUNCS,\n",
        "    args=training_args,\n",
        "    train_dataset=ds,\n",
        ")\n",
        "trainer_res = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "available columns: dict_keys(['loss', 'grad_norm', 'learning_rate', 'num_tokens', 'completions/mean_length', 'completions/min_length', 'completions/max_length', 'completions/clipped_ratio', 'completions/mean_terminated_length', 'completions/min_terminated_length', 'completions/max_terminated_length', 'rewards/numbering_reward_func/mean', 'rewards/numbering_reward_func/std', 'rewards/spelling_reward_func/mean', 'rewards/spelling_reward_func/std', 'rewards/counting_reward_func/mean', 'rewards/counting_reward_func/std', 'rewards/format_reward_func/mean', 'rewards/format_reward_func/std', 'rewards/correct_answer_reward_func/mean', 'rewards/correct_answer_reward_func/std', 'reward', 'reward_std', 'frac_reward_zero_std', 'completion_length', 'kl', 'epoch', 'step'])\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Show the total (sum) of the rewards as well as the correct_answer_reward_func (means with in the batch)\n",
        "# No changes needed in this cell\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# If you want to graph other columns, check these out\n",
        "print(f\"available columns: {trainer.state.log_history[0].keys()}\")\n",
        "\n",
        "log_df = pd.DataFrame(trainer.state.log_history)\n",
        "log_df[\"reward\"].plot()\n",
        "log_df[\"rewards/correct_answer_reward_func/mean\"].plot()\n",
        "\n",
        "# Show the legend\n",
        "plt.legend([\"reward\", \"rewards/correct_answer_reward_func/mean\"])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Slower train (1+ hour)\n",
        "\n",
        "If everything looks good, let's go for a longer training session!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 401 | Num Epochs = 1 | Total steps = 75\n",
            "O^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 2\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 2 x 1) = 16\n",
            " \"-____-\"     Trainable parameters = 59,867,136 of 3,145,805,824 (1.90% trained)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"g\" are there in the word \"glisten\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of g's in the word glisten\n",
            "1. g - 1 so far\n",
            "2. l - 1 so far\n",
            "3. i - 1 so far\n",
            "4. t - 1 so far\n",
            "5. n - 1 so far\n",
            "6. s - 1 so far\n",
            "7. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='75' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [75/75 19:26, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>reward</th>\n",
              "      <th>reward_std</th>\n",
              "      <th>completions / mean_length</th>\n",
              "      <th>completions / min_length</th>\n",
              "      <th>completions / max_length</th>\n",
              "      <th>completions / clipped_ratio</th>\n",
              "      <th>completions / mean_terminated_length</th>\n",
              "      <th>completions / min_terminated_length</th>\n",
              "      <th>completions / max_terminated_length</th>\n",
              "      <th>kl</th>\n",
              "      <th>rewards / numbering_reward_func / mean</th>\n",
              "      <th>rewards / numbering_reward_func / std</th>\n",
              "      <th>rewards / spelling_reward_func / mean</th>\n",
              "      <th>rewards / spelling_reward_func / std</th>\n",
              "      <th>rewards / counting_reward_func / mean</th>\n",
              "      <th>rewards / counting_reward_func / std</th>\n",
              "      <th>rewards / format_reward_func / mean</th>\n",
              "      <th>rewards / format_reward_func / std</th>\n",
              "      <th>rewards / correct_answer_reward_func / mean</th>\n",
              "      <th>rewards / correct_answer_reward_func / std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.066072</td>\n",
              "      <td>3.700518</td>\n",
              "      <td>86.625000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>156.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>86.625000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>156.000000</td>\n",
              "      <td>0.000080</td>\n",
              "      <td>0.756250</td>\n",
              "      <td>0.290330</td>\n",
              "      <td>0.531250</td>\n",
              "      <td>2.877897</td>\n",
              "      <td>0.278571</td>\n",
              "      <td>0.570408</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.894427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.626302</td>\n",
              "      <td>1.976573</td>\n",
              "      <td>78.750000</td>\n",
              "      <td>57.000000</td>\n",
              "      <td>113.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>78.750000</td>\n",
              "      <td>57.000000</td>\n",
              "      <td>113.000000</td>\n",
              "      <td>0.000030</td>\n",
              "      <td>0.898438</td>\n",
              "      <td>0.113823</td>\n",
              "      <td>0.531250</td>\n",
              "      <td>2.759642</td>\n",
              "      <td>0.196615</td>\n",
              "      <td>0.391428</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.032796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.194196</td>\n",
              "      <td>2.604259</td>\n",
              "      <td>76.687500</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>103.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>76.687500</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>103.000000</td>\n",
              "      <td>0.000074</td>\n",
              "      <td>0.801339</td>\n",
              "      <td>0.324099</td>\n",
              "      <td>-0.281250</td>\n",
              "      <td>3.525946</td>\n",
              "      <td>0.799107</td>\n",
              "      <td>0.380627</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>1.024695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.321577</td>\n",
              "      <td>2.190435</td>\n",
              "      <td>82.687500</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>82.687500</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>0.000064</td>\n",
              "      <td>0.947917</td>\n",
              "      <td>0.079786</td>\n",
              "      <td>2.156250</td>\n",
              "      <td>2.942328</td>\n",
              "      <td>-0.032589</td>\n",
              "      <td>0.467531</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.683130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.698958</td>\n",
              "      <td>1.554878</td>\n",
              "      <td>76.062500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>76.062500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>0.000030</td>\n",
              "      <td>0.848958</td>\n",
              "      <td>0.271461</td>\n",
              "      <td>1.406250</td>\n",
              "      <td>3.531849</td>\n",
              "      <td>0.318750</td>\n",
              "      <td>0.530278</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.125000</td>\n",
              "      <td>1.024695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.973549</td>\n",
              "      <td>2.233023</td>\n",
              "      <td>84.687500</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>113.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>84.687500</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>113.000000</td>\n",
              "      <td>0.000047</td>\n",
              "      <td>0.733036</td>\n",
              "      <td>0.236239</td>\n",
              "      <td>-0.406250</td>\n",
              "      <td>2.281949</td>\n",
              "      <td>0.896763</td>\n",
              "      <td>0.219553</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.237946</td>\n",
              "      <td>0.776062</td>\n",
              "      <td>76.125000</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>76.125000</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>0.000152</td>\n",
              "      <td>0.705357</td>\n",
              "      <td>0.124745</td>\n",
              "      <td>-1.500000</td>\n",
              "      <td>1.211060</td>\n",
              "      <td>0.407589</td>\n",
              "      <td>0.530391</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.957427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.039769</td>\n",
              "      <td>1.121672</td>\n",
              "      <td>89.812500</td>\n",
              "      <td>79.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>89.812500</td>\n",
              "      <td>79.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>0.000175</td>\n",
              "      <td>0.856250</td>\n",
              "      <td>0.141946</td>\n",
              "      <td>-0.281250</td>\n",
              "      <td>1.482889</td>\n",
              "      <td>0.464769</td>\n",
              "      <td>0.590700</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.032796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.063951</td>\n",
              "      <td>2.078218</td>\n",
              "      <td>83.750000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>122.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>83.750000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>122.000000</td>\n",
              "      <td>0.000370</td>\n",
              "      <td>0.656250</td>\n",
              "      <td>0.332279</td>\n",
              "      <td>-1.156250</td>\n",
              "      <td>3.118326</td>\n",
              "      <td>0.688951</td>\n",
              "      <td>0.356830</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>1.024695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.264732</td>\n",
              "      <td>0.973852</td>\n",
              "      <td>81.625000</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>104.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>81.625000</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>104.000000</td>\n",
              "      <td>0.000060</td>\n",
              "      <td>0.843750</td>\n",
              "      <td>0.201556</td>\n",
              "      <td>2.062500</td>\n",
              "      <td>3.037954</td>\n",
              "      <td>0.358482</td>\n",
              "      <td>0.404652</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.032796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.726569</td>\n",
              "      <td>1.013888</td>\n",
              "      <td>81.500000</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>81.500000</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>0.000082</td>\n",
              "      <td>0.699107</td>\n",
              "      <td>0.144394</td>\n",
              "      <td>-1.468750</td>\n",
              "      <td>0.921389</td>\n",
              "      <td>0.246212</td>\n",
              "      <td>0.546567</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.755060</td>\n",
              "      <td>1.521973</td>\n",
              "      <td>95.125000</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>196.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>95.125000</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>196.000000</td>\n",
              "      <td>0.000118</td>\n",
              "      <td>0.878125</td>\n",
              "      <td>0.137500</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>1.939717</td>\n",
              "      <td>0.689435</td>\n",
              "      <td>0.382933</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.032796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>3.502232</td>\n",
              "      <td>2.128456</td>\n",
              "      <td>74.062500</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>74.062500</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>0.001090</td>\n",
              "      <td>0.830357</td>\n",
              "      <td>0.219578</td>\n",
              "      <td>-0.593750</td>\n",
              "      <td>2.332515</td>\n",
              "      <td>0.890625</td>\n",
              "      <td>0.240983</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.375000</td>\n",
              "      <td>0.957427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.005915</td>\n",
              "      <td>2.193427</td>\n",
              "      <td>83.437500</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>114.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>83.437500</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>114.000000</td>\n",
              "      <td>0.000592</td>\n",
              "      <td>0.913393</td>\n",
              "      <td>0.105136</td>\n",
              "      <td>0.968750</td>\n",
              "      <td>2.411561</td>\n",
              "      <td>0.248772</td>\n",
              "      <td>0.488133</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>1.024695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.337500</td>\n",
              "      <td>2.051448</td>\n",
              "      <td>71.125000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>114.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>71.125000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>114.000000</td>\n",
              "      <td>0.000617</td>\n",
              "      <td>0.718750</td>\n",
              "      <td>0.340037</td>\n",
              "      <td>0.156250</td>\n",
              "      <td>3.134320</td>\n",
              "      <td>0.837500</td>\n",
              "      <td>0.320156</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.625000</td>\n",
              "      <td>0.806226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.449591</td>\n",
              "      <td>3.076324</td>\n",
              "      <td>81.062500</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>81.062500</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>0.000344</td>\n",
              "      <td>0.808185</td>\n",
              "      <td>0.338752</td>\n",
              "      <td>1.406250</td>\n",
              "      <td>3.406948</td>\n",
              "      <td>0.360156</td>\n",
              "      <td>0.567473</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>1.024695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>2.314286</td>\n",
              "      <td>1.659887</td>\n",
              "      <td>89.625000</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>113.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>89.625000</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>113.000000</td>\n",
              "      <td>0.001014</td>\n",
              "      <td>0.883631</td>\n",
              "      <td>0.161437</td>\n",
              "      <td>-0.625000</td>\n",
              "      <td>2.291288</td>\n",
              "      <td>0.180655</td>\n",
              "      <td>0.529984</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>1.024695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>3.633073</td>\n",
              "      <td>1.761323</td>\n",
              "      <td>86.937500</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>102.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>86.937500</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>102.000000</td>\n",
              "      <td>0.001282</td>\n",
              "      <td>0.912202</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.843750</td>\n",
              "      <td>2.936658</td>\n",
              "      <td>0.252121</td>\n",
              "      <td>0.560984</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.957427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>1.528348</td>\n",
              "      <td>1.424692</td>\n",
              "      <td>84.250000</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>113.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>84.250000</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>113.000000</td>\n",
              "      <td>0.001530</td>\n",
              "      <td>0.654464</td>\n",
              "      <td>0.273362</td>\n",
              "      <td>-1.156250</td>\n",
              "      <td>0.768521</td>\n",
              "      <td>0.655134</td>\n",
              "      <td>0.457027</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.806226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>2.599330</td>\n",
              "      <td>2.451951</td>\n",
              "      <td>89.437500</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>116.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>89.437500</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>116.000000</td>\n",
              "      <td>0.000884</td>\n",
              "      <td>0.786458</td>\n",
              "      <td>0.234459</td>\n",
              "      <td>-0.375000</td>\n",
              "      <td>2.298550</td>\n",
              "      <td>0.437872</td>\n",
              "      <td>0.430381</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>2.734375</td>\n",
              "      <td>2.147919</td>\n",
              "      <td>93.750000</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>115.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>93.750000</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>115.000000</td>\n",
              "      <td>0.001437</td>\n",
              "      <td>0.873214</td>\n",
              "      <td>0.126585</td>\n",
              "      <td>-0.187500</td>\n",
              "      <td>2.096624</td>\n",
              "      <td>0.298661</td>\n",
              "      <td>0.530547</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>5.191369</td>\n",
              "      <td>2.225985</td>\n",
              "      <td>85.562500</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>111.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>85.562500</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>111.000000</td>\n",
              "      <td>0.001331</td>\n",
              "      <td>0.908482</td>\n",
              "      <td>0.125742</td>\n",
              "      <td>1.656250</td>\n",
              "      <td>3.064413</td>\n",
              "      <td>0.501637</td>\n",
              "      <td>0.588438</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.125000</td>\n",
              "      <td>1.024695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>3.331585</td>\n",
              "      <td>1.673207</td>\n",
              "      <td>87.687500</td>\n",
              "      <td>57.000000</td>\n",
              "      <td>128.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>87.687500</td>\n",
              "      <td>57.000000</td>\n",
              "      <td>128.000000</td>\n",
              "      <td>0.001532</td>\n",
              "      <td>0.897321</td>\n",
              "      <td>0.115165</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>1.913766</td>\n",
              "      <td>0.496763</td>\n",
              "      <td>0.445964</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>1.563504</td>\n",
              "      <td>1.194150</td>\n",
              "      <td>97.875000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>175.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>97.875000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>175.000000</td>\n",
              "      <td>0.004837</td>\n",
              "      <td>0.823177</td>\n",
              "      <td>0.203266</td>\n",
              "      <td>-1.343750</td>\n",
              "      <td>1.044330</td>\n",
              "      <td>0.084077</td>\n",
              "      <td>0.519082</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.032796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>2.740402</td>\n",
              "      <td>1.996739</td>\n",
              "      <td>94.187500</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>142.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>94.187500</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>142.000000</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>0.759375</td>\n",
              "      <td>0.370325</td>\n",
              "      <td>-0.156250</td>\n",
              "      <td>2.749053</td>\n",
              "      <td>0.387277</td>\n",
              "      <td>0.512906</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>2.612723</td>\n",
              "      <td>1.363403</td>\n",
              "      <td>101.687500</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>101.687500</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>0.002173</td>\n",
              "      <td>0.883929</td>\n",
              "      <td>0.057588</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>1.505545</td>\n",
              "      <td>0.353795</td>\n",
              "      <td>0.423505</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>1.024695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>4.237165</td>\n",
              "      <td>2.596367</td>\n",
              "      <td>99.750000</td>\n",
              "      <td>84.000000</td>\n",
              "      <td>126.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>99.750000</td>\n",
              "      <td>84.000000</td>\n",
              "      <td>126.000000</td>\n",
              "      <td>0.004018</td>\n",
              "      <td>0.864583</td>\n",
              "      <td>0.126192</td>\n",
              "      <td>0.968750</td>\n",
              "      <td>2.819390</td>\n",
              "      <td>0.403832</td>\n",
              "      <td>0.528734</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.032796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.000600</td>\n",
              "      <td>4.336161</td>\n",
              "      <td>1.230837</td>\n",
              "      <td>81.812500</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>105.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>81.812500</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>105.000000</td>\n",
              "      <td>0.006935</td>\n",
              "      <td>0.889286</td>\n",
              "      <td>0.091473</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>1.973787</td>\n",
              "      <td>0.759375</td>\n",
              "      <td>0.359731</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.625000</td>\n",
              "      <td>0.806226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>2.323661</td>\n",
              "      <td>1.354192</td>\n",
              "      <td>92.375000</td>\n",
              "      <td>83.000000</td>\n",
              "      <td>122.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>92.375000</td>\n",
              "      <td>83.000000</td>\n",
              "      <td>122.000000</td>\n",
              "      <td>0.004608</td>\n",
              "      <td>0.910714</td>\n",
              "      <td>0.143253</td>\n",
              "      <td>-0.625000</td>\n",
              "      <td>1.658312</td>\n",
              "      <td>0.537946</td>\n",
              "      <td>0.480127</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.894427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.000900</td>\n",
              "      <td>4.450893</td>\n",
              "      <td>1.362764</td>\n",
              "      <td>80.187500</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>93.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>80.187500</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>93.000000</td>\n",
              "      <td>0.010707</td>\n",
              "      <td>0.881696</td>\n",
              "      <td>0.154699</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>2.448639</td>\n",
              "      <td>0.256696</td>\n",
              "      <td>0.448967</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.375000</td>\n",
              "      <td>0.957427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.000700</td>\n",
              "      <td>1.579129</td>\n",
              "      <td>1.057890</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>79.000000</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>79.000000</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>0.008721</td>\n",
              "      <td>0.755952</td>\n",
              "      <td>0.161601</td>\n",
              "      <td>-1.156250</td>\n",
              "      <td>0.473242</td>\n",
              "      <td>0.604427</td>\n",
              "      <td>0.503961</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.806226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.000600</td>\n",
              "      <td>2.272169</td>\n",
              "      <td>2.300174</td>\n",
              "      <td>98.687500</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>185.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>98.687500</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>185.000000</td>\n",
              "      <td>0.007131</td>\n",
              "      <td>0.627232</td>\n",
              "      <td>0.439536</td>\n",
              "      <td>-0.468750</td>\n",
              "      <td>3.689936</td>\n",
              "      <td>0.363687</td>\n",
              "      <td>0.577263</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.001200</td>\n",
              "      <td>4.333780</td>\n",
              "      <td>3.032866</td>\n",
              "      <td>90.375000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>139.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>90.375000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>139.000000</td>\n",
              "      <td>0.015210</td>\n",
              "      <td>0.880208</td>\n",
              "      <td>0.107448</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>2.542964</td>\n",
              "      <td>0.703571</td>\n",
              "      <td>0.434868</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.032796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.001700</td>\n",
              "      <td>4.741406</td>\n",
              "      <td>1.502551</td>\n",
              "      <td>86.437500</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>125.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>86.437500</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>125.000000</td>\n",
              "      <td>0.021195</td>\n",
              "      <td>0.880357</td>\n",
              "      <td>0.159666</td>\n",
              "      <td>1.531250</td>\n",
              "      <td>3.216980</td>\n",
              "      <td>0.204799</td>\n",
              "      <td>0.424445</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.125000</td>\n",
              "      <td>1.024695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.000800</td>\n",
              "      <td>5.814062</td>\n",
              "      <td>4.022946</td>\n",
              "      <td>78.250000</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>135.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>78.250000</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>135.000000</td>\n",
              "      <td>0.010482</td>\n",
              "      <td>0.834375</td>\n",
              "      <td>0.434250</td>\n",
              "      <td>2.062500</td>\n",
              "      <td>3.161619</td>\n",
              "      <td>0.542188</td>\n",
              "      <td>0.496212</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.375000</td>\n",
              "      <td>0.957427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>3.700521</td>\n",
              "      <td>3.306508</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>190.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>190.000000</td>\n",
              "      <td>0.012200</td>\n",
              "      <td>0.880208</td>\n",
              "      <td>0.256343</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>3.113813</td>\n",
              "      <td>0.382812</td>\n",
              "      <td>0.617705</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.001800</td>\n",
              "      <td>4.935863</td>\n",
              "      <td>2.375672</td>\n",
              "      <td>91.687500</td>\n",
              "      <td>73.000000</td>\n",
              "      <td>126.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>91.687500</td>\n",
              "      <td>73.000000</td>\n",
              "      <td>126.000000</td>\n",
              "      <td>0.022302</td>\n",
              "      <td>0.930952</td>\n",
              "      <td>0.097202</td>\n",
              "      <td>1.125000</td>\n",
              "      <td>2.735568</td>\n",
              "      <td>0.379911</td>\n",
              "      <td>0.553069</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.894427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.001800</td>\n",
              "      <td>3.105283</td>\n",
              "      <td>0.797886</td>\n",
              "      <td>95.125000</td>\n",
              "      <td>84.000000</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>95.125000</td>\n",
              "      <td>84.000000</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>0.022216</td>\n",
              "      <td>0.966146</td>\n",
              "      <td>0.061273</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>2.713393</td>\n",
              "      <td>0.201637</td>\n",
              "      <td>0.525924</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.806226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.002100</td>\n",
              "      <td>5.073847</td>\n",
              "      <td>2.600734</td>\n",
              "      <td>94.687500</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>94.687500</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>0.025633</td>\n",
              "      <td>0.902530</td>\n",
              "      <td>0.133292</td>\n",
              "      <td>1.875000</td>\n",
              "      <td>2.860653</td>\n",
              "      <td>0.546317</td>\n",
              "      <td>0.353090</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.004000</td>\n",
              "      <td>3.625000</td>\n",
              "      <td>1.888445</td>\n",
              "      <td>92.750000</td>\n",
              "      <td>84.000000</td>\n",
              "      <td>106.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>92.750000</td>\n",
              "      <td>84.000000</td>\n",
              "      <td>106.000000</td>\n",
              "      <td>0.049488</td>\n",
              "      <td>0.881250</td>\n",
              "      <td>0.266278</td>\n",
              "      <td>0.218750</td>\n",
              "      <td>2.456073</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>0.446963</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>1.024695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.001200</td>\n",
              "      <td>5.230915</td>\n",
              "      <td>1.212914</td>\n",
              "      <td>90.312500</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>106.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>90.312500</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>106.000000</td>\n",
              "      <td>0.014769</td>\n",
              "      <td>0.953571</td>\n",
              "      <td>0.084031</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>2.626785</td>\n",
              "      <td>0.652344</td>\n",
              "      <td>0.303597</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.375000</td>\n",
              "      <td>0.957427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.002200</td>\n",
              "      <td>2.073438</td>\n",
              "      <td>1.088298</td>\n",
              "      <td>84.937500</td>\n",
              "      <td>63.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>84.937500</td>\n",
              "      <td>63.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>0.027382</td>\n",
              "      <td>0.706250</td>\n",
              "      <td>0.283945</td>\n",
              "      <td>-1.062500</td>\n",
              "      <td>1.078193</td>\n",
              "      <td>0.554688</td>\n",
              "      <td>0.580416</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>1.024695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.002500</td>\n",
              "      <td>1.909114</td>\n",
              "      <td>1.760750</td>\n",
              "      <td>101.437500</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>125.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>101.437500</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>125.000000</td>\n",
              "      <td>0.031343</td>\n",
              "      <td>0.792969</td>\n",
              "      <td>0.194559</td>\n",
              "      <td>-0.406250</td>\n",
              "      <td>2.990088</td>\n",
              "      <td>0.147396</td>\n",
              "      <td>0.382777</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.806226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.003800</td>\n",
              "      <td>7.408110</td>\n",
              "      <td>1.475892</td>\n",
              "      <td>86.000000</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>106.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>86.000000</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>106.000000</td>\n",
              "      <td>0.047045</td>\n",
              "      <td>0.989583</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>3.406250</td>\n",
              "      <td>2.444168</td>\n",
              "      <td>0.637277</td>\n",
              "      <td>0.299356</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.375000</td>\n",
              "      <td>0.957427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.003900</td>\n",
              "      <td>4.014398</td>\n",
              "      <td>1.758289</td>\n",
              "      <td>93.562500</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>164.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>93.562500</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>164.000000</td>\n",
              "      <td>0.048612</td>\n",
              "      <td>0.799665</td>\n",
              "      <td>0.346799</td>\n",
              "      <td>0.718750</td>\n",
              "      <td>4.651053</td>\n",
              "      <td>0.370982</td>\n",
              "      <td>0.628970</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.125000</td>\n",
              "      <td>1.024695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.001400</td>\n",
              "      <td>5.781696</td>\n",
              "      <td>1.109275</td>\n",
              "      <td>83.750000</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>83.750000</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>0.018038</td>\n",
              "      <td>0.930357</td>\n",
              "      <td>0.133184</td>\n",
              "      <td>1.812500</td>\n",
              "      <td>2.965777</td>\n",
              "      <td>0.663839</td>\n",
              "      <td>0.443942</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.375000</td>\n",
              "      <td>0.957427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.003100</td>\n",
              "      <td>3.965327</td>\n",
              "      <td>2.340059</td>\n",
              "      <td>94.250000</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>164.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>94.250000</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>164.000000</td>\n",
              "      <td>0.039125</td>\n",
              "      <td>0.889881</td>\n",
              "      <td>0.248027</td>\n",
              "      <td>0.093750</td>\n",
              "      <td>2.950812</td>\n",
              "      <td>0.356696</td>\n",
              "      <td>0.613967</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.625000</td>\n",
              "      <td>0.806226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.002200</td>\n",
              "      <td>4.228721</td>\n",
              "      <td>1.071217</td>\n",
              "      <td>87.125000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>104.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>87.125000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>104.000000</td>\n",
              "      <td>0.027770</td>\n",
              "      <td>0.939881</td>\n",
              "      <td>0.081220</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.390444</td>\n",
              "      <td>0.788839</td>\n",
              "      <td>0.282578</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.894427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.002800</td>\n",
              "      <td>7.029688</td>\n",
              "      <td>1.012176</td>\n",
              "      <td>92.375000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>199.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>92.375000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>199.000000</td>\n",
              "      <td>0.034678</td>\n",
              "      <td>0.912500</td>\n",
              "      <td>0.252653</td>\n",
              "      <td>3.312500</td>\n",
              "      <td>3.172145</td>\n",
              "      <td>0.679688</td>\n",
              "      <td>0.500768</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.125000</td>\n",
              "      <td>1.024695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.001600</td>\n",
              "      <td>1.636830</td>\n",
              "      <td>0.512170</td>\n",
              "      <td>94.625000</td>\n",
              "      <td>84.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>94.625000</td>\n",
              "      <td>84.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>0.019618</td>\n",
              "      <td>0.845536</td>\n",
              "      <td>0.159837</td>\n",
              "      <td>-1.531250</td>\n",
              "      <td>0.740917</td>\n",
              "      <td>0.572545</td>\n",
              "      <td>0.537713</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>0.002300</td>\n",
              "      <td>4.054873</td>\n",
              "      <td>1.827796</td>\n",
              "      <td>90.437500</td>\n",
              "      <td>79.000000</td>\n",
              "      <td>106.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>90.437500</td>\n",
              "      <td>79.000000</td>\n",
              "      <td>106.000000</td>\n",
              "      <td>0.028612</td>\n",
              "      <td>0.971726</td>\n",
              "      <td>0.060994</td>\n",
              "      <td>1.062500</td>\n",
              "      <td>3.193092</td>\n",
              "      <td>0.145647</td>\n",
              "      <td>0.442687</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>1.024695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>0.004000</td>\n",
              "      <td>4.186570</td>\n",
              "      <td>1.669837</td>\n",
              "      <td>98.750000</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>119.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>98.750000</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>119.000000</td>\n",
              "      <td>0.050214</td>\n",
              "      <td>0.971726</td>\n",
              "      <td>0.080258</td>\n",
              "      <td>1.375000</td>\n",
              "      <td>3.324154</td>\n",
              "      <td>0.214844</td>\n",
              "      <td>0.571200</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.957427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>0.002500</td>\n",
              "      <td>4.087946</td>\n",
              "      <td>2.993944</td>\n",
              "      <td>87.812500</td>\n",
              "      <td>63.000000</td>\n",
              "      <td>127.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>87.812500</td>\n",
              "      <td>63.000000</td>\n",
              "      <td>127.000000</td>\n",
              "      <td>0.030663</td>\n",
              "      <td>0.844196</td>\n",
              "      <td>0.266397</td>\n",
              "      <td>0.531250</td>\n",
              "      <td>2.848794</td>\n",
              "      <td>0.337500</td>\n",
              "      <td>0.592441</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.375000</td>\n",
              "      <td>0.957427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.002600</td>\n",
              "      <td>3.863058</td>\n",
              "      <td>2.992843</td>\n",
              "      <td>98.250000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>167.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>98.250000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>167.000000</td>\n",
              "      <td>0.032322</td>\n",
              "      <td>0.809821</td>\n",
              "      <td>0.343031</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>2.509150</td>\n",
              "      <td>0.365737</td>\n",
              "      <td>0.589831</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>1.024695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.005000</td>\n",
              "      <td>4.176525</td>\n",
              "      <td>3.878384</td>\n",
              "      <td>93.562500</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>145.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>93.562500</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>145.000000</td>\n",
              "      <td>0.062375</td>\n",
              "      <td>0.809226</td>\n",
              "      <td>0.327239</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>3.581783</td>\n",
              "      <td>0.054799</td>\n",
              "      <td>0.604897</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.375000</td>\n",
              "      <td>0.957427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>0.002100</td>\n",
              "      <td>4.854316</td>\n",
              "      <td>2.297254</td>\n",
              "      <td>93.625000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>118.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>93.625000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>118.000000</td>\n",
              "      <td>0.026085</td>\n",
              "      <td>0.920833</td>\n",
              "      <td>0.093393</td>\n",
              "      <td>1.343750</td>\n",
              "      <td>2.953635</td>\n",
              "      <td>0.464732</td>\n",
              "      <td>0.603005</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.125000</td>\n",
              "      <td>1.024695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>0.003200</td>\n",
              "      <td>4.752456</td>\n",
              "      <td>1.774901</td>\n",
              "      <td>87.875000</td>\n",
              "      <td>78.000000</td>\n",
              "      <td>131.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>87.875000</td>\n",
              "      <td>78.000000</td>\n",
              "      <td>131.000000</td>\n",
              "      <td>0.040314</td>\n",
              "      <td>0.848214</td>\n",
              "      <td>0.343764</td>\n",
              "      <td>1.718750</td>\n",
              "      <td>3.021968</td>\n",
              "      <td>0.060491</td>\n",
              "      <td>0.357303</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.125000</td>\n",
              "      <td>1.024695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>0.002600</td>\n",
              "      <td>2.818192</td>\n",
              "      <td>3.159023</td>\n",
              "      <td>98.687500</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>199.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>98.687500</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>199.000000</td>\n",
              "      <td>0.032579</td>\n",
              "      <td>0.787500</td>\n",
              "      <td>0.328753</td>\n",
              "      <td>-0.593750</td>\n",
              "      <td>2.922435</td>\n",
              "      <td>0.499442</td>\n",
              "      <td>0.632227</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.125000</td>\n",
              "      <td>1.024695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>0.003900</td>\n",
              "      <td>6.156176</td>\n",
              "      <td>2.413910</td>\n",
              "      <td>90.375000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>123.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>90.375000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>123.000000</td>\n",
              "      <td>0.048709</td>\n",
              "      <td>0.945238</td>\n",
              "      <td>0.084846</td>\n",
              "      <td>2.250000</td>\n",
              "      <td>2.857738</td>\n",
              "      <td>0.585938</td>\n",
              "      <td>0.314355</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.375000</td>\n",
              "      <td>0.957427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.003300</td>\n",
              "      <td>6.589397</td>\n",
              "      <td>2.079115</td>\n",
              "      <td>88.500000</td>\n",
              "      <td>61.000000</td>\n",
              "      <td>118.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>88.500000</td>\n",
              "      <td>61.000000</td>\n",
              "      <td>118.000000</td>\n",
              "      <td>0.041757</td>\n",
              "      <td>0.944196</td>\n",
              "      <td>0.107074</td>\n",
              "      <td>2.531250</td>\n",
              "      <td>2.929555</td>\n",
              "      <td>0.238951</td>\n",
              "      <td>0.443415</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.875000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61</td>\n",
              "      <td>0.003700</td>\n",
              "      <td>7.417708</td>\n",
              "      <td>2.865876</td>\n",
              "      <td>86.187500</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>97.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>86.187500</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>97.000000</td>\n",
              "      <td>0.045868</td>\n",
              "      <td>0.968155</td>\n",
              "      <td>0.069263</td>\n",
              "      <td>3.906250</td>\n",
              "      <td>2.353853</td>\n",
              "      <td>0.543304</td>\n",
              "      <td>0.528574</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.032796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>0.002300</td>\n",
              "      <td>3.322247</td>\n",
              "      <td>2.540307</td>\n",
              "      <td>96.500000</td>\n",
              "      <td>79.000000</td>\n",
              "      <td>115.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>96.500000</td>\n",
              "      <td>79.000000</td>\n",
              "      <td>115.000000</td>\n",
              "      <td>0.028894</td>\n",
              "      <td>0.874702</td>\n",
              "      <td>0.111266</td>\n",
              "      <td>-0.062500</td>\n",
              "      <td>2.015564</td>\n",
              "      <td>0.385045</td>\n",
              "      <td>0.588247</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.125000</td>\n",
              "      <td>1.024695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>0.003900</td>\n",
              "      <td>5.392709</td>\n",
              "      <td>1.924188</td>\n",
              "      <td>88.187500</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>88.187500</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>0.049149</td>\n",
              "      <td>0.914286</td>\n",
              "      <td>0.104848</td>\n",
              "      <td>1.468750</td>\n",
              "      <td>2.837069</td>\n",
              "      <td>0.509673</td>\n",
              "      <td>0.504158</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.894427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>0.002400</td>\n",
              "      <td>1.576823</td>\n",
              "      <td>1.786171</td>\n",
              "      <td>97.937500</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>176.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>97.937500</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>176.000000</td>\n",
              "      <td>0.030019</td>\n",
              "      <td>0.849702</td>\n",
              "      <td>0.246934</td>\n",
              "      <td>-1.218750</td>\n",
              "      <td>1.632674</td>\n",
              "      <td>-0.179129</td>\n",
              "      <td>0.389767</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.125000</td>\n",
              "      <td>1.024695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>0.003100</td>\n",
              "      <td>2.188430</td>\n",
              "      <td>2.899554</td>\n",
              "      <td>104.625000</td>\n",
              "      <td>79.000000</td>\n",
              "      <td>189.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>104.625000</td>\n",
              "      <td>79.000000</td>\n",
              "      <td>189.000000</td>\n",
              "      <td>0.038648</td>\n",
              "      <td>0.848214</td>\n",
              "      <td>0.247264</td>\n",
              "      <td>-0.843750</td>\n",
              "      <td>2.809026</td>\n",
              "      <td>0.183966</td>\n",
              "      <td>0.612920</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.032796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>0.003600</td>\n",
              "      <td>6.511979</td>\n",
              "      <td>3.198419</td>\n",
              "      <td>80.875000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>139.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>80.875000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>139.000000</td>\n",
              "      <td>0.044995</td>\n",
              "      <td>0.941667</td>\n",
              "      <td>0.089856</td>\n",
              "      <td>2.812500</td>\n",
              "      <td>2.920474</td>\n",
              "      <td>0.257812</td>\n",
              "      <td>0.450807</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.894427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67</td>\n",
              "      <td>0.002300</td>\n",
              "      <td>3.079688</td>\n",
              "      <td>1.958288</td>\n",
              "      <td>96.187500</td>\n",
              "      <td>79.000000</td>\n",
              "      <td>145.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>96.187500</td>\n",
              "      <td>79.000000</td>\n",
              "      <td>145.000000</td>\n",
              "      <td>0.028945</td>\n",
              "      <td>0.801786</td>\n",
              "      <td>0.280227</td>\n",
              "      <td>-0.343750</td>\n",
              "      <td>2.364450</td>\n",
              "      <td>0.246652</td>\n",
              "      <td>0.670764</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.375000</td>\n",
              "      <td>0.957427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>0.007400</td>\n",
              "      <td>4.624702</td>\n",
              "      <td>2.138891</td>\n",
              "      <td>90.812500</td>\n",
              "      <td>73.000000</td>\n",
              "      <td>106.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>90.812500</td>\n",
              "      <td>73.000000</td>\n",
              "      <td>106.000000</td>\n",
              "      <td>0.092903</td>\n",
              "      <td>0.854167</td>\n",
              "      <td>0.242479</td>\n",
              "      <td>0.593750</td>\n",
              "      <td>2.697028</td>\n",
              "      <td>0.676786</td>\n",
              "      <td>0.388154</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.894427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>0.002600</td>\n",
              "      <td>4.332812</td>\n",
              "      <td>1.964395</td>\n",
              "      <td>78.437500</td>\n",
              "      <td>61.000000</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>78.437500</td>\n",
              "      <td>61.000000</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>0.032026</td>\n",
              "      <td>0.837500</td>\n",
              "      <td>0.114746</td>\n",
              "      <td>0.156250</td>\n",
              "      <td>1.921100</td>\n",
              "      <td>0.589062</td>\n",
              "      <td>0.354256</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.750000</td>\n",
              "      <td>0.683130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.003000</td>\n",
              "      <td>5.494494</td>\n",
              "      <td>2.220995</td>\n",
              "      <td>91.375000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>153.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>91.375000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>153.000000</td>\n",
              "      <td>0.037121</td>\n",
              "      <td>0.956101</td>\n",
              "      <td>0.081756</td>\n",
              "      <td>1.968750</td>\n",
              "      <td>2.777701</td>\n",
              "      <td>0.569643</td>\n",
              "      <td>0.404114</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.032796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71</td>\n",
              "      <td>0.002800</td>\n",
              "      <td>5.140848</td>\n",
              "      <td>1.791816</td>\n",
              "      <td>98.125000</td>\n",
              "      <td>79.000000</td>\n",
              "      <td>136.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>98.125000</td>\n",
              "      <td>79.000000</td>\n",
              "      <td>136.000000</td>\n",
              "      <td>0.035614</td>\n",
              "      <td>0.892857</td>\n",
              "      <td>0.139849</td>\n",
              "      <td>1.281250</td>\n",
              "      <td>2.994266</td>\n",
              "      <td>0.591741</td>\n",
              "      <td>0.450723</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.375000</td>\n",
              "      <td>0.957427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>0.003100</td>\n",
              "      <td>3.162723</td>\n",
              "      <td>1.196455</td>\n",
              "      <td>85.437500</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>108.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>85.437500</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>108.000000</td>\n",
              "      <td>0.038791</td>\n",
              "      <td>0.861607</td>\n",
              "      <td>0.175388</td>\n",
              "      <td>0.406250</td>\n",
              "      <td>2.782198</td>\n",
              "      <td>0.394866</td>\n",
              "      <td>0.507044</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.894427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73</td>\n",
              "      <td>0.003100</td>\n",
              "      <td>4.784970</td>\n",
              "      <td>1.360577</td>\n",
              "      <td>85.375000</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>128.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>85.375000</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>128.000000</td>\n",
              "      <td>0.038359</td>\n",
              "      <td>0.929688</td>\n",
              "      <td>0.157908</td>\n",
              "      <td>2.093750</td>\n",
              "      <td>3.465154</td>\n",
              "      <td>0.011533</td>\n",
              "      <td>0.296143</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>0.003200</td>\n",
              "      <td>5.041852</td>\n",
              "      <td>1.713135</td>\n",
              "      <td>93.125000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>155.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>93.125000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>155.000000</td>\n",
              "      <td>0.039700</td>\n",
              "      <td>0.887277</td>\n",
              "      <td>0.208933</td>\n",
              "      <td>1.562500</td>\n",
              "      <td>3.655476</td>\n",
              "      <td>0.592076</td>\n",
              "      <td>0.474495</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.032796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>0.003200</td>\n",
              "      <td>5.923438</td>\n",
              "      <td>3.725987</td>\n",
              "      <td>86.062500</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>166.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>86.062500</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>166.000000</td>\n",
              "      <td>0.040221</td>\n",
              "      <td>0.872768</td>\n",
              "      <td>0.254206</td>\n",
              "      <td>2.406250</td>\n",
              "      <td>3.158158</td>\n",
              "      <td>0.519420</td>\n",
              "      <td>0.530800</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.125000</td>\n",
              "      <td>1.024695</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"e\" are there in the word \"sapphire\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of e's in the word \"sapphire\"\n",
            "1. s - 0 so far\n",
            "2. a - 1 so far\n",
            "3. p - 1 so far\n",
            "4. a - 2 so far\n",
            "5. p - 2 so far\n",
            "6. h - 2 so far\n",
            "7. a - 3 so far\n",
            "8. y - 3 so far\n",
            "9. e - 3 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "3\n",
            "</answer>\n",
            "Extracted: 3\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"g\" are there in the word \"absolve\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of g's in the word absolve\n",
            "1. a - 0 so far\n",
            "2. b - 0 so far\n",
            "3. s - 1 so far\n",
            "4. a - 1 so far\n",
            "5. b - 1 so far\n",
            "6. o - 1 so far\n",
            "7. g - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"g\" are there in the word \"mirage\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of \"g\" in the word \"mirage\"\n",
            "1. m - 0 so far\n",
            "2. i - 0 so far\n",
            "3. r - 0 so far\n",
            "4. a - 0 so far\n",
            "5. g - 1 so far\n",
            "6. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"r\" are there in the word \"crave\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of r's in the word crave\n",
            "1. c - 0 so far\n",
            "2. r - 1 so far\n",
            "3. a - 1 so far\n",
            "4. v - 1 so far\n",
            "5. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"y\" are there in the word \"frescos\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of y's in the word frescos\n",
            "1. f - 0 so far\n",
            "2. r - 0 so far\n",
            "3. e - 0 so far\n",
            "4. s - 0 so far\n",
            "5. c - 0 so far\n",
            "6. o - 0 so far\n",
            "7. s - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"v\" are there in the word \"absolve\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of v's in the word absolve\n",
            "1. a - 0 so far\n",
            "2. b - 1 so far\n",
            "3. s - 1 so far\n",
            "4. v - 1 so far\n",
            "...\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"i\" are there in the word \"eclipse\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of i's in the word eclipse\n",
            "1. e - 1 so far\n",
            "2. l - 1 so far\n",
            "3. c - 1 so far\n",
            "4. p - 1 so far\n",
            "5. l - 2 so far\n",
            "6. c - 3 so far\n",
            "7. e - 4 so far\n",
            "8. e - 5 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "5\n",
            "</answer>\n",
            "Extracted: 5\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"e\" are there in the word \"echo\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of \"e\" in the word \"echo\"\n",
            "1. e - 1 so far\n",
            "2. ch - 0 so far\n",
            "3. o - 0 so far\n",
            "4. c - 0 so far\n",
            "5. h - 0 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"d\" are there in the word \"void\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of d's in the word void\n",
            "1. v - 0 so far\n",
            "2. o - 1 so far\n",
            "3. o - 2 so far\n",
            "4. i - 3 so far\n",
            "5. d - 4 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "4\n",
            "</answer>\n",
            "Extracted: 4\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"o\" are there in the word \"ivory\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of o's in the word ivory\n",
            "1. i - 1 so far\n",
            "2. v - 1 so far\n",
            "3. r - 1 so far\n",
            "4. i - 2 so far\n",
            "5. o - 3 so far\n",
            "6. o - 4 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "4\n",
            "</answer>\n",
            "Extracted: 4\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"p\" are there in the word \"aperture\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of p's in the word aperture\n",
            "1. a - 0 so far\n",
            "2. p - 1 so far\n",
            "3. a - 1 so far\n",
            "4. p - 2 so far\n",
            "5. t - 2 so far\n",
            "6. e - 2 so far\n",
            "7. r - 2 so far\n",
            "8. u - 2 so far\n",
            "9. e - 3 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "3\n",
            "</answer>\n",
            "Extracted: 3\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"m\" are there in the word \"fume\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of m's in the word \"fume\"\n",
            "1. f - 0 so far\n",
            "2. u - 0 so far\n",
            "3. m - 1 so far\n",
            "4. e - 1 so far\n",
            "5. m - 2 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"c\" are there in the word \"crave\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of [letter_to_count]'s in the word [word]\n",
            "1. c - 1 so far\n",
            "2. r - 1\n",
            "3. a - 1\n",
            "4. v - 0\n",
            "5. e - 0\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"f\" are there in the word \"frescos\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of f's in the word frescos\n",
            "1. f - 1 so far\n",
            "2. r - 1 so far\n",
            "3. e - 1 so far\n",
            "4. s - 1 so far\n",
            "5. c - 1 so far\n",
            "6. o - 1 so far\n",
            "7. s - 1 so far\n",
            "Total count of f's: 1\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"b\" are there in the word \"banner\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of b's in the word banner\n",
            "1. b - 1 so far\n",
            "2. a\n",
            "3. n\n",
            "4. b\n",
            "5. a\n",
            "6. r\n",
            "7. b\n",
            "8. n\n",
            "9. - (no more b's)\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"x\" are there in the word \"capture\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of x's in the word capture\n",
            "1. c - 1 so far\n",
            "2. a - 1 so far\n",
            "3. p - 1 so far\n",
            "4. r - 1 so far\n",
            "5. e - 1 so far\n",
            "6. a - 2 so far\n",
            "7. x - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"p\" are there in the word \"sphinx\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of [letter_to_count]'s in the word [word]\n",
            "1. s - 0 so far\n",
            "2. p - 1 so far\n",
            "3. h - 1 so far\n",
            "4. n - 1 so far\n",
            "5. k - 1 so far\n",
            "6. p - 2 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"k\" are there in the word \"knack\"\n",
            "Answer: 2\n",
            "Response: <reasoning>\n",
            "Counting the number of k's in the word knack\n",
            "1. n - 0 so far\n",
            "2. k - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"r\" are there in the word \"relish\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of r's in the word relish\n",
            "1. r - 1 so far\n",
            "2. r - 1 + 1 = 2 so far\n",
            "3. l - 2 so far\n",
            "4. e - 2 so far\n",
            "5. r - 2 + 1 = 3 so far\n",
            "6. i - 3 so far\n",
            "7. s - 3 so far\n",
            "8. h - 3 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "3\n",
            "</answer>\n",
            "Extracted: 3\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"r\" are there in the word \"zealous\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of r's in the word zealous\n",
            "1. z - 0 so far\n",
            "2. e - 0 so far\n",
            "3. a - 0 so far\n",
            "4. l - 0 so far\n",
            "5. o - 0 so far\n",
            "6. s - 0 so far\n",
            "7. a - 1 so far\n",
            "8. z - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"g\" are there in the word \"idea\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of g's in the word idea\n",
            "1. i - 0 so far\n",
            "2. d - 0 so far\n",
            "3. e - 0 so far\n",
            "4. a - 0 so far\n",
            "5. g - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"t\" are there in the word \"tavern\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of t's in the word tavern\n",
            "1. t - 1 so far\n",
            "2. a - 1 so far\n",
            "3. v - 1 so far\n",
            "4. a - 2 so far\n",
            "5. r - 2 so far\n",
            "6. n - 2 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"s\" are there in the word \"sapphire\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of s's in the word sapphire\n",
            "1. s - 1 so far\n",
            "2. a - 0 (count of requested letter so far remains 1)\n",
            "3. p - 0 (count of requested letter so far remains 1)\n",
            "4. a - 0 (count of requested letter so far remains 1)\n",
            "5. p - 0 (count of requested letter so far remains 1)\n",
            "6. a - 0 (count of requested letter so far remains 1)\n",
            "7. p - 0 (count of requested letter so far remains 1)\n",
            "8. h - 0 (count of requested letter so far remains 1)\n",
            "9. y - 0 (count of requested letter so far remains 1)\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"a\" are there in the word \"mantle\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of a's in the word mantle\n",
            "1. m - 0 so far\n",
            "2. a - 1 so far\n",
            "3. n - 1 so far\n",
            "4. a - 2 so far\n",
            "5. l - 2 so far\n",
            "6. e - 2 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"i\" are there in the word \"whistle\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of [letter_to_count]'s in the word [word]\n",
            "1. w - 0 so far\n",
            "2. h - 0 so far\n",
            "3. i - 0 so far\n",
            "4. s - 0 so far\n",
            "5. t - 0 so far\n",
            "6. l - 0 so far\n",
            "7. e - 0 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"p\" are there in the word \"torrent\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of [letter_to_count]'s in the word [word]\n",
            "1. t - 1 so far\n",
            "2. o - 0 so far\n",
            "3. r - 1 so far\n",
            "4. o - 1 so far\n",
            "5. v - 0 so far\n",
            "6. e - 1 so far\n",
            "7. n - 0 so far\n",
            "8. t - 2 so far\n",
            "There are no \"p\"s in the word \"torrent\".\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"w\" are there in the word \"brawn\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of w's in the word brawn\n",
            "1. b - 0 so far\n",
            "2. r - 0 so far\n",
            "3. w - 1 so far\n",
            "4. n - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"m\" are there in the word \"fathom\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of m's in the word \"fathom\"\n",
            "1. f - 0 so far\n",
            "2. m - 1 so far\n",
            "3. a - 1 so far\n",
            "4. m - 2 so far\n",
            "5. o - 2 so far\n",
            "6. m - 3 so far\n",
            "7. n - 3 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "3\n",
            "</answer>\n",
            "Extracted: 3\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"x\" are there in the word \"echo\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of x's in the word echo\n",
            "1. e - 0 so far\n",
            "2. c - 0 so far\n",
            "3. h - 0 so far\n",
            "4. o - 0 so far\n",
            "5. o - 1 so far\n",
            "6. x - 0 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"n\" are there in the word \"enchant\"\n",
            "Answer: 2\n",
            "Response: <reasoning>\n",
            "Counting the number of n's in the word enchant\n",
            "1. e - 0 so far\n",
            "2. n - 1 so far\n",
            "3. a - 1 so far\n",
            "4. c - 1 so far\n",
            "5. h - 1 so far\n",
            "6. t - 1 so far\n",
            "7. n - 2 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"h\" are there in the word \"lush\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of h's in the word \"lush\"\n",
            "1. l - 0 so far\n",
            "2. u - 0 so far\n",
            "3. s - 0 so far\n",
            "4. h - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"n\" are there in the word \"fusion\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of n's in the word fusion\n",
            "1. f - 0 so far\n",
            "2. u - 0 so far\n",
            "3. n - 1 so far\n",
            "4. i - 0 so far\n",
            "5. s - 0 so far\n",
            "6. u - 0 so far\n",
            "7. n - 2 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"w\" are there in the word \"maze\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of [letter_to_count]'s in the word [word]\n",
            "1. m - 0 so far\n",
            "2. a - 1 so far\n",
            "3. z - 0 so far\n",
            "4. e - 1 so far\n",
            "There are no occurrences of the letter \"w\" in the word \"maze\".\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"t\" are there in the word \"onset\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of t's in the word onset\n",
            "1. o - 0 \n",
            "2. n - 0\n",
            "3. s - 0\n",
            "4. e - 0\n",
            "5. t - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"o\" are there in the word \"veto\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of o's in the word veto\n",
            "1. v - 0 so far\n",
            "2. e - 0 so far\n",
            "3. t - 0 so far\n",
            "4. o - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"y\" are there in the word \"ivory\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of [letter_to_count]'s in the word [word]\n",
            "1. i - 0 so far\n",
            "2. v - 0 so far\n",
            "3. o - 1 so far\n",
            "4. r - 1 so far\n",
            "5. y - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"n\" are there in the word \"torrent\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of n's in the word \"torrent\"\n",
            "1. t - 0 so far\n",
            "2. o - 0 so far\n",
            "3. r - 0 so far\n",
            "4. o - 1 so far\n",
            "5. t - 1 so far\n",
            "6. e - 1 so far\n",
            "7. r - 2 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"e\" are there in the word \"whistle\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of e's in the word whistle\n",
            "1. w - 0 so far\n",
            "2. h - 0 so far\n",
            "3. i - 0 so far\n",
            "4. s - 0 so far\n",
            "5. t - 0 so far\n",
            "6. e - 1 so far\n",
            "7. l - 0 so far\n",
            "8. l - 0 so far\n",
            "9. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"c\" are there in the word \"resolve\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of [letter_to_count]'s in the word [word]\n",
            "1. l - 0 so far\n",
            "2. o - 1 so far\n",
            "3. v - 0 so far\n",
            "4. e - 2 so far\n",
            "5. s - 1 so far\n",
            "6. c - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"i\" are there in the word \"mirage\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of [letter_to_count]'s in the word [word]\n",
            "1. m - 0 so far\n",
            "2. i - 1 so far\n",
            "3. r - 0 so far\n",
            "4. a - 1 so far\n",
            "5. g - 0 so far\n",
            "6. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"r\" are there in the word \"lunar\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of [letter_to_count]'s in the word [word]\n",
            "1. l - 0 so far\n",
            "2. u - 0 so far\n",
            "3. a - 0 so far\n",
            "4. n - 0 so far\n",
            "5. r - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"i\" are there in the word \"sapphire\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of [letter_to_count]'s in the word [word]\n",
            "1. s - 0 so far\n",
            "2. a - 0 so far\n",
            "3. p - 0 so far\n",
            "4. a - 1 so far\n",
            "5. s - 1 so far\n",
            "6. p - 2 so far\n",
            "7. h - 2 so far\n",
            "8. a - 3 so far\n",
            "9. y - 3 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "3\n",
            "</answer>\n",
            "Extracted: 3\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"t\" are there in the word \"mantle\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of t's in the word \"mantle\"\n",
            "1. m - 0 so far\n",
            "2. a - 0 so far\n",
            "3. n - 0 so far\n",
            "4. t - 1 so far\n",
            "5. l - 1 so far\n",
            "6. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"p\" are there in the word \"sapphire\"\n",
            "Answer: 2\n",
            "Response: <reasoning>\n",
            "Counting the number of [letter_to_count]'s in the word [word]\n",
            "1. s - 0 so far\n",
            "2. a - 1 so far\n",
            "3. p - 1 so far\n",
            "...\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"r\" are there in the word \"ivory\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of r's in the word \"ivory\"\n",
            "1. i - 0 so far\n",
            "2. v - 0 so far\n",
            "3. i - 1 so far\n",
            "4. r - 1 so far\n",
            "5. v - 1 so far\n",
            "6. o - 1 so far\n",
            "7. y - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"i\" are there in the word \"triumph\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of [letter_to_count]'s in the word [word]\n",
            "1. [first letter] - [count of requested letter so far] so far\n",
            "2. [second letter] - [count of requested letter so far] so far\n",
            "3. [third letter] - [count of requested letter so far] so far\n",
            "4. [fourth letter] - [count of requested letter so far] so far\n",
            "5. [fifth letter] - [count of requested letter so far] so far\n",
            "6. [sixth letter] - [count of requested letter so far] so far\n",
            "7. [seventh letter] - [count of requested letter so far] so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"s\" are there in the word \"zealous\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of s's in the word zealous\n",
            "1. z - 0 so far\n",
            "2. e - 0 so far\n",
            "3. a - 0 so far\n",
            "4. l - 0 so far\n",
            "5. o - 0 so far\n",
            "6. s - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"e\" are there in the word \"verge\"\n",
            "Answer: 2\n",
            "Response: <reasoning>\n",
            "Counting the number of [letter_to_count]'s in the word [word]\n",
            "1. v - 0 so far\n",
            "2. e - 1 so far\n",
            "3. r - 1 so far\n",
            "4. g - 1 so far\n",
            "5. e - 2 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"l\" are there in the word \"onset\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of [letter_to_count]'s in the word [word]\n",
            "1. o - 0 so far\n",
            "2. n - 1 so far\n",
            "3. o - 1 so far\n",
            "4. s - 2 so far\n",
            "5. e - 3 so far\n",
            "6. t - 4 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "4\n",
            "</answer>\n",
            "Extracted: 4\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"c\" are there in the word \"crisp\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of [letter_to_count]'s in the word [word]\n",
            "1. c - 1 so far\n",
            "2. r - 0 so far\n",
            "3. i - 0 so far\n",
            "4. s - 0 so far\n",
            "5. p - 0 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"f\" are there in the word \"lantern\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of [letter_to_count]'s in the word [word]\n",
            "1. l - 0 so far\n",
            "2. a - 0 so far\n",
            "3. n - 0 so far\n",
            "4. t - 0 so far\n",
            "5. e - 0 so far\n",
            "6. r - 0 so far\n",
            "7. n - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"h\" are there in the word \"fusion\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of [letter_to_count]'s in the word [word]\n",
            "1. f - 0 so far\n",
            "2. u - 0 so far\n",
            "3. i - 0 so far\n",
            "4. n - 0 so far\n",
            "5. s - 0 so far\n",
            "6. o - 0 so far\n",
            "So, the number of letter \"h\" in the word \"fusion\" is 0.\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"o\" are there in the word \"onset\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. o - 1 so far\n",
            "2. n - 1 so far\n",
            "3. s - 0 so far\n",
            "4. e - 0 so far\n",
            "5. t - 0 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"r\" are there in the word \"wisp\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of [letter_to_count]'s in the word [word]\n",
            "1. w - 0 so far\n",
            "2. i - 1 so far\n",
            "3. s - 2 so far\n",
            "4. p - 3 so far\n",
            "...\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"a\" are there in the word \"radius\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of a's in the word radius\n",
            "1. r - 0 so far\n",
            "2. a - 1 so far\n",
            "3. a - 1 (total is now 2) so far\n",
            "4. s - 2 so far\n",
            "5. i - 2 so far\n",
            "6. d - 2 so far\n",
            "7. a - 3 (total is now 3) so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "3\n",
            "</answer>\n",
            "Extracted: 3\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"w\" are there in the word \"elude\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of [letter_to_count]'s in the word [word]\n",
            "1. e - 1 so far\n",
            "2. l - 1 so far\n",
            "3. u - 1 so far\n",
            "4. d - 1 so far\n",
            "5. e - 2 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"a\" are there in the word \"enchant\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of a's in the word \"enchant\"\n",
            "1. e - 0 so far\n",
            "2. n - 0 so far\n",
            "3. c - 0 so far\n",
            "4. h - 0 so far\n",
            "5. a - 1 so far\n",
            "6. n - 1 so far\n",
            "7. t - 1 so far\n",
            "8. n - 2 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"h\" are there in the word \"orchard\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of [letter_to_count]'s in the word [word]\n",
            "1. o - 0 so far\n",
            "2. r - 0 so far\n",
            "3. a - 0 so far\n",
            "4. c - 0 so far\n",
            "5. h - 0 so far\n",
            "6. h - 1 so far\n",
            "7. d - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"m\" are there in the word \"maze\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of [letter_to_count]'s in the word [word]\n",
            "1. m - 1 so far\n",
            "2. a - 1, m - 1 so far\n",
            "3. z - 0, a - 1, m - 1 so far\n",
            "4. e - 0, a - 1, m - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"e\" are there in the word \"mantle\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of [letter_to_count]'s in the word [word]\n",
            "1. m - [count of requested letter so far] so far\n",
            "2. a - 1 so far\n",
            "3. n - 1 so far\n",
            "4. t - 1 so far\n",
            "5. l - 1 so far\n",
            "6. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"h\" are there in the word \"gossipy\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of h's in the word gossipy\n",
            "1. g - 0 so far\n",
            "2. o - 0 so far\n",
            "3. s - 0 so far\n",
            "4. s - 0 so far\n",
            "5. i - 0 so far\n",
            "6. p - 0 so far\n",
            "7. y - 0 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"h\" are there in the word \"ivory\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of [letter_to_count]'s in the word [word]\n",
            "1. i - 1 so far\n",
            "2. v - 1 so far\n",
            "3. o - 1 so far\n",
            "4. r - 1 so far\n",
            "5. y - 1 so far\n",
            "6. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"r\" are there in the word \"capture\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of \"r\" in the word \"capture\"\n",
            "1. c - 0 so far\n",
            "2. a - 0 so far\n",
            "3. p - 0 so far\n",
            "4. r - 1 so far\n",
            "5. c - 1 so far\n",
            "6. a - 1 so far\n",
            "7. t - 1 so far\n",
            "8. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"e\" are there in the word \"prelude\"\n",
            "Answer: 2\n",
            "Response: <reasoning>\n",
            "Counting the number of [letter_to_count]'s in the word [word]\n",
            "1. p - 0 so far\n",
            "2. r - 0 so far\n",
            "3. e - 1 so far\n",
            "4. p - 1 so far\n",
            "5. l - 1 so far\n",
            "6. u - 1 so far\n",
            "7. e - 2 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"r\" are there in the word \"crisp\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of [letter_to_count]'s in the word [word]\n",
            "1. c - 0 so far\n",
            "2. r - 1 so far\n",
            "3. i - 0 so far\n",
            "4. s - 1 so far\n",
            "5. p - 0 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"t\" are there in the word \"enchant\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of t's in the word enchant\n",
            "1. e - 0 so far\n",
            "2. n - 1 so far\n",
            "3. c - 2 so far\n",
            "4. h - 3 so far\n",
            "5. a - 4 so far\n",
            "6. n - 5 so far\n",
            "7. t - 6 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"c\" are there in the word \"scarab\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of c's in the word \"scarab\"\n",
            "1. s - 0 so far\n",
            "2. c - 1 so far\n",
            "3. a - 1 so far\n",
            "4. r - 1 so far\n",
            "5. a - 2 so far\n",
            "6. b - 2 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"a\" are there in the word \"oath\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. o - 0 so far\n",
            "2. a - 1 so far\n",
            "3. h - 0 so far\n",
            "Therefore, there is 1 letter \"a\" in the word \"oath\".\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"k\" are there in the word \"prelude\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of [letter_to_count]'s in the word [word]\n",
            "1. p - [count of requested letter so far] so far\n",
            "2. r - [count of requested letter so far] so far\n",
            "3. e - [count of requested letter so far] so far\n",
            "4. l - [count of requested letter so far] so far\n",
            "5. u - [count of requested letter so far] so far\n",
            "6. d - [count of requested letter so far] so far\n",
            "7. e - [count of requested letter so far] so far\n",
            "So far, there are 0 occurrences of the letter \"k\".\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"m\" are there in the word \"mantle\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of [letter_to_count]'s in the word [word]\n",
            "1. m - 1 so far\n",
            "2. a - 1 so far\n",
            "3. n - 1 so far\n",
            "4. t - 1 so far\n",
            "5. l - 1 so far\n",
            "6. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"f\" are there in the word \"grim\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of [letter_to_count]'s in the word [word]\n",
            "1. g - 0 so far\n",
            "2. r - 0 so far\n",
            "3. i - 0 so far\n",
            "4. m - 0 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"h\" are there in the word \"oath\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of [letter_to_count]'s in the word [word]\n",
            "1. o - 0 so far\n",
            "2. a - 1 so far\n",
            "3. h - 0 so far\n",
            "4. h - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"e\" are there in the word \"aperture\"\n",
            "Answer: 2\n",
            "Response: <reasoning>\n",
            "Counting the number of [letter_to_count]'s in the word [word]\n",
            "1. a - 1 so far\n",
            "2. p - 0 so far\n",
            "3. e - 0 so far\n",
            "...\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"s\" are there in the word \"rust\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of s's in the word \"rust\"\n",
            "1. r - 0 so far\n",
            "2. u - 0 so far\n",
            "3. s - 1 so far\n",
            "4. t - 1 so far\n",
            "5. s - 2 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n"
          ]
        }
      ],
      "source": [
        "# Now let's train for real! Let's do a longer training that will take an hour or more\n",
        "# Note: If this run is successful, you can consider doing a longer train\n",
        "# to see what happens, but that's beyond the scope of this project.\n",
        "# TODO: Fill out the areas where you find **********\n",
        "\n",
        "# Full training\n",
        "training_args = GRPOConfig(\n",
        "    **COMMON_GRPO_TRAINING_PARAMS,\n",
        "    # Configure the maximum number of steps to take about 30mins of time for\n",
        "    # a medium-sized experiment. (See how long the previous example took and\n",
        "    # scale up appropriately using your best guess.)\n",
        "    max_steps=225,  # ~60min\n",
        ")\n",
        "trainer = GRPOTrainer(\n",
        "    model=model,\n",
        "    processing_class=tokenizer,\n",
        "    reward_funcs=REWARD_FUNCS,\n",
        "    args=training_args,\n",
        "    train_dataset=ds,\n",
        ")\n",
        "trainer_res = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "available columns: dict_keys(['loss', 'grad_norm', 'learning_rate', 'num_tokens', 'completions/mean_length', 'completions/min_length', 'completions/max_length', 'completions/clipped_ratio', 'completions/mean_terminated_length', 'completions/min_terminated_length', 'completions/max_terminated_length', 'rewards/numbering_reward_func/mean', 'rewards/numbering_reward_func/std', 'rewards/spelling_reward_func/mean', 'rewards/spelling_reward_func/std', 'rewards/counting_reward_func/mean', 'rewards/counting_reward_func/std', 'rewards/format_reward_func/mean', 'rewards/format_reward_func/std', 'rewards/correct_answer_reward_func/mean', 'rewards/correct_answer_reward_func/std', 'reward', 'reward_std', 'frac_reward_zero_std', 'completion_length', 'kl', 'epoch', 'step'])\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Show the total (sum) of the rewards as well as the correct_answer_reward_func (means with in the batch)\n",
        "# Do you see the rewards increasing? Does the model get the correct answer\n",
        "# more frequently toward the end?\n",
        "# No changes needed in this cell\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# If you want to graph other columns, check these out\n",
        "print(f\"available columns: {trainer.state.log_history[0].keys()}\")\n",
        "\n",
        "log_df = pd.DataFrame(trainer.state.log_history)\n",
        "log_df[\"reward\"].plot()\n",
        "log_df[\"rewards/correct_answer_reward_func/mean\"].plot()\n",
        "\n",
        "# Show the legend\n",
        "plt.legend([\"reward\", \"rewards/correct_answer_reward_func/mean\"])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## View the results\n",
        "Now let's try the model we just trained!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the LoRA adapters\n",
        "# No changes needed in this cell\n",
        "\n",
        "# Save the LoRA model\n",
        "model.save_lora(\"grpo_saved_lora\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a function to run both the original model and the updated model\n",
        "# No changes needed in this cell\n",
        "\n",
        "\n",
        "def compare_old_and_new_model(messages):\n",
        "    from vllm import SamplingParams\n",
        "\n",
        "    text = tokenizer.apply_chat_template(\n",
        "        messages, tokenize=False, add_generation_prompt=True\n",
        "    )\n",
        "\n",
        "    sampling_params = SamplingParams(\n",
        "        temperature=0.8,\n",
        "        top_p=0.95,\n",
        "        max_tokens=1024,\n",
        "    )\n",
        "    old = (\n",
        "        model.fast_generate(\n",
        "            text,\n",
        "            sampling_params=sampling_params,\n",
        "        )[0]\n",
        "        .outputs[0]\n",
        "        .text\n",
        "    )\n",
        "\n",
        "    new = (\n",
        "        model.fast_generate(\n",
        "            text,\n",
        "            sampling_params=sampling_params,\n",
        "            lora_request=model.load_lora(\"grpo_saved_lora\"),\n",
        "        )[0]\n",
        "        .outputs[0]\n",
        "        .text\n",
        "    )\n",
        "\n",
        "    print(\"===OLD===\\n\")\n",
        "    print(old)\n",
        "\n",
        "    print(\"\\n\\n===NEW===\\n\")\n",
        "    print(new)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Compare the old and new models on the letter-counting task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Let's try spelling the first word from the dataset\n",
        "# TODO: Fill out the areas where you find **********\n",
        "\n",
        "# Load the first item from the dataset (index 0) and compare the old and new models\n",
        "# **********\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Our model is better at spelling and counter letters in words! Depending on your reward functions, the size of your model, and the amount of steps trained, results may vary.\n",
        "\n",
        "For about an hour of training time, your model may not be perfect (or maybe it is), but it's definitely moving in the right direction!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Make sure the model did not forget basic facts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Let's see if the model still remembers some of the facts from its original training\n",
        "# TODO: Fill out the areas where you find **********\n",
        "\n",
        "# Ask both the old and new models a question the model is likely to know,\n",
        "# e.g. a well-known capital city\n",
        "# **********\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Great job! Congrats on completing the project! ðŸŽ‰ðŸ¤—"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
